---
title: "Practica 3 AID 2025"
output: html_document
---



# 1. Conceptos Básicos de un Test de Hipótesis

## 1.1. Hipótesis Nula (H₀) y Alternativa (H₁)
Un **test de hipótesis** es un procedimiento estadístico para tomar decisiones sobre una afirmación (hipótesis) acerca de una característica de la población.

- **Hipótesis nula (H₀):** Generalmente plantea “no existe efecto” o “no hay diferencia”.  
- **Hipótesis alternativa (H₁):** Plantea lo contrario, es decir, que sí existe efecto o diferencia.

## 1.2. Errores de Tipo I y Tipo II

- **Error Tipo I (\(\alpha\))**  
  Se comete cuando **rechazamos H₀** siendo ésta **verdadera**. A menudo se denomina “falso positivo”.  
  \[
    \alpha = P(\text{rechazar H₀} \mid H₀ \text{ es verdadera}).
  \]

- **Error Tipo II (\(\beta\))**  
  Ocurre cuando **no se rechaza H₀** siendo ésta **falsa**. Se le denomina “falso negativo”.  
  \[
    \beta = P(\text{no rechazar H₀} \mid H₀ \text{ es falsa}).
  \]

## 1.3. Nivel de Significación y Potencia

- **Nivel de significación (\(\alpha\)):**  
  Es la probabilidad máxima que aceptamos para cometer un Error Tipo I. Usualmente se fija en 0.05 o 0.01.  
- **Potencia de la prueba (\(1-\beta\)):**  
  Es la probabilidad de **rechazar H₀** cuando realmente es falsa. Cuanto más alta sea la potencia, más sensible es el test para detectar efectos reales.

\[
    1 - \beta = P(\text{rechazar H₀} \mid H₀ \text{ es falsa}).
\]


# 2. Relación entre \(\alpha\), \(\beta\) y Tamaño de la Muestra

1. **Para un nivel de significación \(\alpha\) dado:**  
   - Al **aumentar** el **tamaño muestral** (\(n\)), **disminuye** \(\beta\).  
   - Esto implica que se **incrementa** la **potencia** (\(1 - \beta\)).  

2. **Para un tamaño de muestra fijo:**  
   - Al **disminuir** \(\alpha\), **aumenta** \(\beta\).  
   - Al **aumentar** \(\alpha\), **disminuye** \(\beta\).  

Dicho de otra manera, si reducimos mucho \(\alpha\) para ser más conservadores (menor probabilidad de falso positivo), a la vez aumentamos la probabilidad de no detectar un efecto real (falso negativo).


# 3. Curvas de \(\beta\) (Operación Característica) y \(1-\beta\) (Potencia)

- **Curva de Operación Característica (COC):** Muestra cómo evoluciona \(\beta\) (probabilidad de no rechazar H₀ cuando es falsa) frente a cambios en parámetros como el tamaño de la muestra, el efecto o \(\alpha\).  
- **Curva de Potencia:** Muestra \(1 - \beta\), la probabilidad de rechazar H₀ correctamente cuando es falsa, según el mismo tipo de variaciones.

Ambas curvas son importantes para planificar estudios:  
- La **Curva de Potencia** ayuda a decidir cuán grande debe ser la muestra para detectar un efecto de cierto tamaño con la probabilidad deseada.  
- La **COC** puede usarse también como referencia para ver la probabilidad de cometer un falso negativo en distintos escenarios.




> **Supuestos para simplificar**:  
> - Prueba de hipótesis a dos colas para una media, con desviación estándar conocida igual a 1.  
> - H₀: \(\mu = 0\).  
> - H₁: \(\mu \neq 0\).  
> - El “efecto” real (verdadera media \(\mu\)) se asume diferente de 0; por ejemplo, \(\mu = 1\).  
> - \(\alpha\) tomará algunos valores típicos (0.01, 0.05, 0.1).  
> - \(n\) variará en un rango (por ej., 5 a 100).  

## 4. Cálculo de \(\beta\) (Error Tipo II)

Para una prueba de dos colas, se rechaza H₀ si \(\lvert Z \rvert > z_{\alpha/2}\), donde \(Z \sim \mathcal{N}(\delta, 1)\).  
- \(\delta\) es el verdadero desplazamiento de la media en unidades de error estándar, \(\delta = \frac{\text{(media real - media hipotética)} \times \sqrt{n}}{\sigma}\).  
- \(\beta = P(\text{no rechazar H₀} \mid \text{H₀ es falsa})\).  
- Entonces, \(\beta = P(-z_{\alpha/2} \leq Z \leq z_{\alpha/2})\).  

Matemáticamente, para \(Z \sim \mathcal{N}(\delta,1)\):
\[
  \beta = \Phi\bigl(z_{\alpha/2} - \delta\bigr) \;-\; \Phi\bigl(-z_{\alpha/2} - \delta\bigr).
\]

Donde \(\Phi\) es la función de distribución acumulada de la Normal Estándar.


```{r}


library(ggplot2)

# Definimos la función para calcular Beta en una prueba de 2 colas:
calc_beta <- function(n, alpha, efecto = 1, sigma = 1) {
  z_alpha_2 <- qnorm(1 - alpha / 2)  # valor crítico
  # delta es el desplazamiento (media real - media hipotética) * sqrt(n)/sigma
  delta <- (efecto * sqrt(n)) / sigma
  
  # Probabilidad de no rechazar H0
  beta_val <- pnorm(z_alpha_2 - delta) - pnorm(-z_alpha_2 - delta)
  return(beta_val)
}

# Distintos valores de alpha
alpha_values <- c(0.01, 0.05, 0.10)
# Rango de tamaños de muestra
n_values <- seq(5, 100, by = 5)

# Construimos un data frame con todas las combinaciones de n y alpha
df_beta <- expand.grid(
  n = n_values,
  alpha = alpha_values
)

# Calculamos Beta para cada combinación
df_beta$Beta <- mapply(
  calc_beta,
  n = df_beta$n,
  alpha = df_beta$alpha
)

# Graficamos Beta vs n, con distintas curvas para cada alpha
ggplot(df_beta, aes(x = n, y = Beta, color = factor(alpha))) +
  geom_line(size = 1) +
  geom_point() +
  labs(
    title = "Curva de Operacion Caracteristica: Beta vs. Tamano muestral",
    x = "Tamano de la muestra (n)",
    y = expression(beta),
    color = expression(alpha)
  ) +
  theme_minimal()
```

**Interpretación del gráfico de Beta (\(\beta\)):**  
- Para una media real \(\mu = 1\) (efecto de 1 unidad), se observa que a mayor \(n\), menor \(\beta\).  
- A su vez, para un mismo \(n\), valores más grandes de \(\alpha\) implican \(\beta\) más baja.  


## 4.2. Curva de Potencia (\(1 - \beta\)) vs. Tamaño de la Muestra

La **potencia** es \(1 - \beta\). Representa la probabilidad de **rechazar H₀** (correctamente) cuando en realidad hay un efecto. Graficarla nos muestra qué tan “sensible” es nuestro test con distintos tamaños de muestra y distintos niveles de significancia.

```{r}
# Agregamos la columna "Potencia" = 1 - Beta
df_beta$Potencia <- 1 - df_beta$Beta

# Graficamos la Curva de Potencia vs n, para cada alpha
ggplot(df_beta, aes(x = n, y = Potencia, color = factor(alpha))) +
  geom_line(size = 1) +
  geom_point() +
  labs(
    title = "Curva de Potencia: (1 - Beta) vs. Tamano muestral",
    x = "Tamano de la muestra (n)",
    y = "Potencia = 1 - Beta",
    color = expression(alpha)
  ) +
  theme_minimal()
```

**Interpretación del gráfico de Potencia (\(1 - \beta\)):**  
- A medida que aumenta \(n\), la potencia se aproxima a 1 (test más capaz de detectar diferencias reales).  
- Para un mismo \(n\), un \(\alpha\) mayor también eleva la probabilidad de rechazar H₀, por lo que la potencia aumenta.

```{r}

calc_beta <- function(n, alpha, delta, sigma = 1) {
  z_alpha_2 <- qnorm(1 - alpha / 2)
  # delta estandarizado: (delta * sqrt(n)) / sigma
  delta_std <- (delta * sqrt(n)) / sigma
  # Beta = P(-z_alpha_2 <= Z - delta_std <= z_alpha_2) para Z ~ N(0,1)
  beta_val <- pnorm(z_alpha_2 - delta_std) - pnorm(-z_alpha_2 - delta_std)
  return(beta_val)
}

# Parametros fijos y rangos
n_fijo <- 30
alpha_values <- c(0.01, 0.05, 0.10)
delta_values <- seq(-1.5, 1.5, by = 0.005)

df_beta_delta <- expand.grid(delta = delta_values, alpha = alpha_values)

df_beta_delta$Beta <- mapply(
  function(a, d) calc_beta(n_fijo, a, d),
  df_beta_delta$alpha,
  df_beta_delta$delta
)

ggplot(df_beta_delta, aes(x = delta, y = Beta, color = factor(alpha))) +
  geom_line(size = 1) +
  labs(
    title = "Beta vs Delta con n=30",
    x = "Delta (diferencia)",
    y = "Beta",
    color = expression(alpha)
  ) +
  theme_minimal()

```

```{r}
# Parametros fijos y rangos
n_fijo <- 300
alpha_values <- c(0.01, 0.05, 0.10)
delta_values <- seq(-1.5, 1.5, by = 0.005)

df_beta_delta <- expand.grid(delta = delta_values, alpha = alpha_values)

df_beta_delta$Beta <- mapply(
  function(a, d) calc_beta(n_fijo, a, d),
  df_beta_delta$alpha,
  df_beta_delta$delta
)

ggplot(df_beta_delta, aes(x = delta, y = Beta, color = factor(alpha))) +
  geom_line(size = 1) +
  labs(
    title = "Beta vs Delta con n=300",
    x = "Delta (diferencia)",
    y = "Beta",
    color = expression(alpha)
  ) +
  theme_minimal()
```

# 5. Ejemplo de Prueba de Hipótesis y Cálculo de p‑valor

Aunque el foco principal es mostrar la relación entre \(\alpha\), \(\beta\) y \(n\), también recordamos el concepto de **p‑valor**:

1. **p‑valor pequeño (ej. < 0.05):** Evidencia para rechazar H₀.  
2. **p‑valor grande:** No hay evidencia suficiente para rechazar H₀.

### 5.1. Simulación y Cálculo del p‑valor

```{r}
set.seed(100)

# Simulamos datos donde la media real es 10.5, sd=2, n=40
muestra <- rnorm(40, mean = 10.5, sd = 2)

media_muestra <- mean(muestra)
sd_muestra <- sd(muestra)
n <- length(muestra)
media_hipotetica <- 10

# Estadístico z para H0: mu = 10 vs H1: mu != 10
error_estandar <- sd_muestra / sqrt(n)
z_stat <- (media_muestra - media_hipotetica) / error_estandar
p_valor <- 2 * (1 - pnorm(abs(z_stat)))  # prueba a dos colas

cat("Media de la muestra:", round(media_muestra, 2), "\n")
cat("Estadistico z:", round(z_stat, 2), "\n")
cat("p-valor:", round(p_valor, 4), "\n")
```

**Interpretación:**  
- Si \(\text{p-valor} < \alpha\) (por ejemplo, 0.05), se rechaza H₀.  
- Si \(\text{p-valor} \geq \alpha\), no se puede rechazar H₀.

### 5.2. Visualización del p‑valor en la Distribución Normal

```{r}
# Distribución Normal Estándar
x <- seq(-4, 4, length.out = 1000)
densidad <- dnorm(x)
df <- data.frame(x = x, densidad = densidad)

valor_obs <- 1.5  # Ejemplo de estadístico observado
p_valor_ej <- 2 * (1 - pnorm(abs(valor_obs)))

ggplot(df, aes(x = x, y = densidad)) +
  geom_line(size = 1) +
  # Area en las dos colas más extremas que valor_obs
  geom_area(data = subset(df, x >= valor_obs),
            aes(x = x, y = densidad), alpha = 0.4) +
  geom_area(data = subset(df, x <= -valor_obs),
            aes(x = x, y = densidad), alpha = 0.4) +
  labs(
    title = "Distribucion Normal y Region del p-valor",
    subtitle = paste("Valor observado =", valor_obs,
                     "| p-valor =", round(p_valor_ej, 4)),
    x = "Valores",
    y = "Densidad"
  ) +
  theme_minimal()
```

> En la gráfica, las áreas sombreadas en las colas representan la probabilidad (p‑valor) de obtener un valor igual o más extremo que 1.5 (o -1.5) bajo H₀.



## 3. Ejemplos 

### 3.1. Ejemplo 1: Test de Hipótesis para la Media de una Distribución Normal

Imaginemos que queremos comprobar si la media de una variable es 10.  
Generamos una muestra de datos con una media real de 10.5 y evaluamos la hipótesis:

- **H₀:** µ = 10  
- **H₁:** µ ≠ 10

Calcularemos el p‑valor de forma manual usando la función `pnorm`.

```{r}
set.seed(123)
# Simular una muestra de 30 datos de una distribución normal con media 10.5 y desviación 2
muestra <- rnorm(30, mean = 10.5, sd = 2)
media_muestra <- mean(muestra)
sd_muestra <- sd(muestra)
n <- length(muestra)

# Valor hipotético
media_hipotetica <- 10

# Calcular el error estándar
error_est <- sd_muestra / sqrt(n)

# Calcular el estadístico z (usando la aproximación normal)
z <- (media_muestra - media_hipotetica) / error_est

# p-valor para una prueba de dos colas
p_valor_manual <- 2 * (1 - pnorm(abs(z)))
cat("Media de la muestra:", round(media_muestra, 2), "\n")
cat("Estadistico z:", round(z, 2), "\n")
cat("p-valor:", round(p_valor_manual, 4), "\n")
```

*Interpretación:*  
Si el p‑valor es menor que 0.05, se rechaza H₀, lo que sugeriría que la media es significativamente diferente de 10.

### 3.2. Ejemplo 2: Test de Hipótesis en un Experimento de Lanzamiento de Moneda

Supongamos que lanzamos una moneda 100 veces y queremos comprobar si es justa (probabilidad de cara = 0.5).  
- **H₀:** La moneda es justa (p = 0.5)  
- **H₁:** La moneda no es justa (p ≠ 0.5)

Simulamos los lanzamientos y calculamos el p‑valor usando la distribución binomial.

```{r}
set.seed(456)
# Simular 100 lanzamientos de moneda (0 = cruz, 1 = cara)
lanzamientos <- rbinom(100, size = 1, prob = 0.5)
caras <- sum(lanzamientos)

# Supongamos que se obtuvieron 'caras' caras. 
# Calcular el p-valor para una prueba de dos colas usando la función pbinom.
p_valor_binom <- 2 * min(
  pbinom(caras, size = 100, prob = 0.5),
  1 - pbinom(caras - 1, size = 100, prob = 0.5)
)
cat("Número de caras:", caras, "\n")
cat("p-valor (binomial):", round(p_valor_binom, 4), "\n")
```

*Visualización:*  
Podemos graficar la distribución binomial y señalar el área correspondiente al p‑valor.

```{r}
# Crear secuencia de posibles resultados
x_vals <- 0:100
densidad_binom <- dbinom(x_vals, size = 100, prob = 0.5)
df_binom <- data.frame(x = x_vals, densidad = densidad_binom)

# Valor observado (número de caras)
valor_obs_binom <- caras

ggplot(df_binom, aes(x = x, y = densidad)) +
  geom_bar(stat = "identity", fill = "lightblue", color = "black") +
  geom_vline(xintercept = valor_obs_binom, color = "red", size = 1) +
  labs(title = "Distribución Binomial (n = 100, p = 0.5)",
       subtitle = paste("Número de caras =", valor_obs_binom),
       x = "Número de caras",
       y = "Probabilidad") +
  theme_minimal()
```



## 4. Ejercicios

### Ejercicio 1: Media de una Distribución Normal  
-   
  Simulen una muestra de 40 datos de una distribución normal con media 15 y desviación 3. Planteen la hipótesis:  
  - H₀: La media es 14.  
  - H₁: La media es diferente de 14.  
  Calcular el estadístico (z) y el p‑valor manualmente.  
- **Pista:** Use funciones `rnorm()`, `mean()`, `sd()`, y `pnorm()`.

### Ejercicio 2: Visualización del p‑valor  
-   
  Utilizando ggplot2, grafiquen la distribución normal estándar y marquen la región que corresponde al p‑valor para un valor observado de 2.2 en una prueba de dos colas.  
- **Pista:** Use `geom_area()` para sombrear las colas de la distribución.

### Ejercicio 3: Experimento de Lanzamiento de Moneda  
-   
  Simulen 200 lanzamientos de una moneda (con probabilidad 0.5) y supongan que obtuvieron un número inusual de caras (por ejemplo, 130).  
  Calcular el p‑valor usando la distribución binomial y explique si se rechazaría la hipótesis de moneda justa (usando α = 0.05).  
- **Pista:** Use `rbinom()`, `pbinom()` y visualice la distribución.

### Ejercicio 4: Comparación de Dos Grupos Simulados  
-   
  Simulen dos grupos independientes de 50 observaciones cada uno:  
  - Grupo A: datos generados con media 20 y desviación 4.  
  - Grupo B: datos generados con media 22 y desviación 4.  
  Planteen la hipótesis de que no existe diferencia en las medias entre los grupos (H₀: µₐ = µ_b).  
  Realicen lo siguiente:  
  1. Calcular la diferencia de medias observada.  
  2. Utilizar un método de re-muestreo (simulación) para generar la distribución de la diferencia de medias bajo H₀ (por ejemplo, mezclando ambos grupos y extrayendo muestras aleatorias).  
  3. Calcular el p‑valor como la proporción de simulaciones en las que la diferencia absoluta es mayor o igual a la observada.  
  4. Visualizar la distribución de las diferencias de medias simuladas y marcar la diferencia observada.  
- **Pista:** Use funciones como `sample()`, `replicate()` y ggplot2 para la visualización.


## 5. Resoluciones de los Ejercicios

### Resolución Ejercicio 1

```{r}
set.seed(101)
# Simular 40 datos con media = 15 y sd = 3
muestra_e1 <- rnorm(40, mean = 15, sd = 3)
media_muestra_e1 <- mean(muestra_e1)
sd_muestra_e1 <- sd(muestra_e1)
n_e1 <- length(muestra_e1)

# Hipótesis: H₀: µ = 14, H₁: µ ≠ 14
media_hipotetica_e1 <- 14
error_est_e1 <- sd_muestra_e1 / sqrt(n_e1)
z_e1 <- (media_muestra_e1 - media_hipotetica_e1) / error_est_e1
p_valor_e1 <- 2 * (1 - pnorm(abs(z_e1)))

cat("Media de la muestra:", round(media_muestra_e1,2), "\n")
cat("Estadístico z:", round(z_e1,2), "\n")
cat("p-valor:", round(p_valor_e1,4), "\n")
```

### Resolución Ejercicio 2

```{r}
library(ggplot2)
# Distribución normal estándar
x <- seq(-4, 4, length.out = 1000)
df2 <- data.frame(x = x, densidad = dnorm(x))
valor_obs_e2 <- 2.2
p_valor_e2 <- 2 * (1 - pnorm(valor_obs_e2))

ggplot(df2, aes(x = x, y = densidad)) +
  geom_line(color = "blue", size = 1) +
  geom_area(data = subset(df2, x >= valor_obs_e2), aes(y = densidad), fill = "red", alpha = 0.4) +
  geom_area(data = subset(df2, x <= -valor_obs_e2), aes(y = densidad), fill = "red", alpha = 0.4) +
  labs(title = "Distribución Normal Estándar y Región del p-valor",
       subtitle = paste("Valor observado =", valor_obs_e2, "| p-valor =", round(p_valor_e2,4)),
       x = "Valores", y = "Densidad") +
  theme_minimal()
```

### Resolución Ejercicio 3

```{r}
set.seed(202)
# Simular 200 lanzamientos de moneda
lanzamientos_e3 <- rbinom(200, size = 1, prob = 0.5)
caras_e3 <- sum(lanzamientos_e3)

# Supongamos que se obtuvieron 130 caras en la simulación
# Para efectos del ejercicio, forzamos el valor:
caras_e3 <- 130

# Calcular el p-valor para una prueba de dos colas
p_valor_binom_e3 <- 2 * min(
  pbinom(caras_e3, size = 200, prob = 0.5),
  1 - pbinom(caras_e3 - 1, size = 200, prob = 0.5)
)

cat("Número de caras:", caras_e3, "\n")
cat("p-valor (binomial):", round(p_valor_binom_e3,4), "\n")

# Con α = 0.05, si el p-valor es menor, se rechaza la hipótesis de moneda justa.
```

### Resolución Ejercicio 4 (Integrador)

```{r}
set.seed(303)
# Simular dos grupos de 50 observaciones
grupo_A <- rnorm(50, mean = 20, sd = 4)
grupo_B <- rnorm(50, mean = 22, sd = 4)

# Diferencia de medias observada
diff_obs <- mean(grupo_B) - mean(grupo_A)
cat("Diferencia observada (B - A):", round(diff_obs,2), "\n")

# Combinamos ambos grupos para simular bajo H₀ (no hay diferencia)
datos_combinados <- c(grupo_A, grupo_B)
n_total <- length(datos_combinados)

# Número de simulaciones
simulaciones <- 5000
diferencias_sim <- replicate(simulaciones, {
  # Mezclar aleatoriamente y dividir en dos grupos de igual tamaño
  permutacion <- sample(datos_combinados, n_total, replace = FALSE)
  grupo1 <- permutacion[1:50]
  grupo2 <- permutacion[51:100]
  mean(grupo2) - mean(grupo1)
})

# Calcular el p-valor como la proporción de simulaciones en las que
# la diferencia absoluta es mayor o igual a la observada
p_valor_sim <- mean(abs(diferencias_sim) >= abs(diff_obs))
cat("p-valor (simulación):", round(p_valor_sim,4), "\n")

# Visualización de la distribución de diferencias simuladas
df_sim <- data.frame(diferencia = diferencias_sim)

ggplot(df_sim, aes(x = diferencia)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
  geom_vline(xintercept = diff_obs, color = "red", size = 1.2) +
  geom_vline(xintercept = -diff_obs, color = "red", size = 1.2) +
  labs(title = "Distribución de Diferencias de Medias (Simulaciones)",
       subtitle = paste("Diferencia Observada =", round(diff_obs,2),
                        "| p-valor =", round(p_valor_sim,4)),
       x = "Diferencia de Medias", y = "Frecuencia") +
  theme_minimal()
```

*Interpretación:*  
El método de re-muestreo nos permite aproximar la distribución de la diferencia de medias bajo la hipótesis nula. Si el p‑valor es pequeño (por ejemplo, menor a 0.05), se concluye que es poco probable observar una diferencia tan grande por azar, lo que sugiere que los grupos difieren en sus medias.


A continuación se presenta una clase muy detallada (para 2 horas) en la que se abordan los conceptos de **Errores Tipo I y Tipo II**, **Potencia de la Prueba** y **Test de Independencia**. La clase incluye explicaciones teóricas, ejemplos prácticos en R (con visualizaciones usando ggplot2 cuando aplica) y ejercicios con sus resoluciones, de modo que los estudiantes construyan una base sólida para futuras aplicaciones en inferencia estadística.



## 3. Test de Independencia

### 3.1. Concepto y Uso

El **test de independencia** se utiliza para determinar si dos variables categóricas son estadísticamente independientes. Por lo general, se emplea el test chi-cuadrado de independencia.

- **Hipótesis:**
  - **H₀:** Las dos variables son independientes.
  - **H₁:** Existe una asociación (dependencia) entre las dos variables.

### 3.2. Ejemplo Práctico con Datos Simulados

Imaginemos un escenario donde se evalúa la relación entre el género (Masculino, Femenino) y la preferencia por un producto (Sí, No).

```{r}
# Crear una tabla de contingencia simulada
genero <- c(rep("Masculino", 60), rep("Femenino", 40))
preferencia <- c(sample(c("Sí", "No"), 60, replace = TRUE, prob = c(0.7, 0.3)),
                 sample(c("Sí", "No"), 40, replace = TRUE, prob = c(0.4, 0.6)))
datos_cat <- data.frame(genero, preferencia)

# Crear la tabla de contingencia
tabla_contingencia <- table(datos_cat$genero, datos_cat$preferencia)
print(tabla_contingencia)

# Realizar el test de chi-cuadrado de independencia
test_independencia <- chisq.test(tabla_contingencia)
print(test_independencia)
```

*Interpretación:*  
Si el p‑valor es menor a 0.05 se rechaza H₀, indicando que existe una asociación entre el género y la preferencia por el producto.

### 3.3. Visualización de la Tabla de Contingencia


```{r}
library(ggplot2)

# Create the plot
ggplot(datos_cat, aes(x = genero, fill = preferencia)) +
  geom_bar(position = "fill") +  # "fill" makes it proportional
  labs(title = "Distribución de Preferencia por Género",
       x = "Género",
       y = "Proporción",
       fill = "Preferencia") +
  theme_minimal()

```


## 4. Ejercicios

### Ejercicio 1: Errores Tipo I y Tipo II  
-   
  Simule una muestra de 50 datos con una media de 12 y desviación 3. Plantee la prueba:  
  - H₀: µ = 10  
  - H₁: µ ≠ 10  
  Calcule el estadístico de prueba, el p‑valor y discuta en qué situaciones podría incurrirse en un Error Tipo I o en un Error Tipo II.

### Ejercicio 2: Potencia de la Prueba  
-   
  Utilice la función `power.t.test()` para determinar el tamaño muestral necesario para alcanzar una potencia de al menos 0.85, considerando un tamaño del efecto (diferencia) de 2, una desviación estándar de 3 y un nivel de significancia de 0.05.

### Ejercicio 3: Test de Independencia  
-   
  Dado el siguiente conjunto de datos simulados que representan la relación entre el tipo de estudio (Presencial, Virtual) y la satisfacción (Alta, Media, Baja) de los estudiantes, realice lo siguiente:  
  1. Construya la tabla de contingencia.  
  2. Realice el test de chi-cuadrado para determinar si existe una relación entre las dos variables.  
  3. Visualice los resultados utilizando un gráfico de mosaico.  

> *Pista:* Puede crear los datos utilizando la función `sample()`.

### Ejercicio 4 (Integrador y más extenso):  
-   
  Combine los conceptos de errores, potencia y test de independencia en el siguiente escenario:  
  1. Simule dos grupos de estudiantes de 100 observaciones cada uno, donde se mida la nota final. Suponga que el Grupo A tiene una media de 75 y el Grupo B de 80 (con desviación 10).  
  2. Realice una prueba (utilizando el enfoque de re-muestreo o métodos paramétricos) para determinar si existe una diferencia en las medias.  
  3. Calcule la potencia de la prueba para detectar dicha diferencia.  
  4. Además, simule una variable categórica “asistencia” (Alta, Baja) y verifique si existe asociación entre el grupo de estudio (A o B) y la asistencia mediante un test de independencia.  
  5. Visualice los resultados de ambas pruebas.


## 5. Resoluciones de los Ejercicios

### Resolución Ejercicio 1: Errores Tipo I y Tipo II

```{r}
set.seed(2021)
# Simular 50 datos con media = 12 y sd = 3
muestra_e1 <- rnorm(50, mean = 12, sd = 3)
media_muestra_e1 <- mean(muestra_e1)
sd_muestra_e1 <- sd(muestra_e1)
n_e1 <- length(muestra_e1)

# Hipótesis: H₀: µ = 10, H₁: µ ≠ 10
media_hip_e1 <- 10
error_est_e1 <- sd_muestra_e1 / sqrt(n_e1)
z_e1 <- (media_muestra_e1 - media_hip_e1) / error_est_e1
p_valor_e1 <- 2 * (1 - pnorm(abs(z_e1)))

cat("Media de la muestra:", round(media_muestra_e1,2), "\n")
cat("Estadístico z:", round(z_e1,2), "\n")
cat("p-valor:", round(p_valor_e1,4), "\n")
```

*Comentario:*  
- Si el p‑valor es menor a 0.05, se rechaza H₀.  
- Cometer un Error Tipo I implicaría rechazar H₀ cuando la media real fuera 10.  
- Un Error Tipo II se cometería si no se rechaza H₀ aun cuando la media real sea 12.



### Resolución Ejercicio 2: Potencia de la Prueba

```{r}
# Determinar el tamaño muestral necesario para una potencia de 0.85
resultado_potencia <- power.t.test(delta = 2, sd = 3, sig.level = 0.05, power = 0.85,
                                   type = "two.sample", alternative = "two.sided")
print(resultado_potencia)
```

*Comentario:*  
El resultado indicará el tamaño muestral necesario por grupo para alcanzar una potencia de al menos 85% dado el tamaño del efecto y la variabilidad propuesta.



### Resolución Ejercicio 3: Test de Independencia

```{r}
# Simulación de datos: Tipo de estudio y Satisfacción
set.seed(123)
tipo_estudio <- sample(c("Presencial", "Virtual"), size = 150, replace = TRUE, prob = c(0.6, 0.4))
satisfaccion <- sample(c("Alta", "Media", "Baja"), size = 150, replace = TRUE, prob = c(0.5, 0.3, 0.2))
datos_e3 <- data.frame(tipo_estudio, satisfaccion)

# Tabla de contingencia
tabla_e3 <- table(datos_e3$tipo_estudio, datos_e3$satisfaccion)
print(tabla_e3)

# Test de chi-cuadrado de independencia
test_e3 <- chisq.test(tabla_e3)
print(test_e3)

library(ggplot2)

# Create the stacked bar chart
ggplot(datos_e3, aes(x = tipo_estudio, fill = satisfaccion)) +
  geom_bar(position = "fill") +  # "fill" makes it proportional
  labs(title = "Distribución de Satisfacción por Tipo de Estudio",
       x = "Tipo de Estudio",
       y = "Proporción",
       fill = "Satisfacción") +
  theme_minimal()

```

*Comentario:*  
Si el p‑valor del test chi-cuadrado es menor a 0.05, se rechaza la hipótesis de independencia, indicando que existe una asociación entre el tipo de estudio y el nivel de satisfacción.



### Resolución Ejercicio 4 (Integrador)

```{r}
set.seed(555)
# 1. Simulación de notas para dos grupos
grupo_A <- rnorm(100, mean = 75, sd = 10)
grupo_B <- rnorm(100, mean = 80, sd = 10)

# Diferencia observada en las medias
diff_obs <- mean(grupo_B) - mean(grupo_A)
cat("Diferencia observada (B - A):", round(diff_obs,2), "\n")

# 2. Prueba de diferencia de medias (enfoque paramétrico)
# Estadístico t para muestras independientes:
n1 <- n2 <- 100
var_pooled <- (((n1-1)*var(grupo_A)) + ((n2-1)*var(grupo_B)))/(n1+n2-2)
error_est_diff <- sqrt(var_pooled*(1/n1 + 1/n2))
t_stat <- diff_obs / error_est_diff
p_valor_diff <- 2*(1 - pt(abs(t_stat), df = n1+n2-2))
cat("t:", round(t_stat,2), " - p-valor:", round(p_valor_diff,4), "\n")

# 3. Calcular la potencia de la prueba
potencia_integrador <- power.t.test(n = 100, delta = diff_obs, sd = sqrt(var_pooled), sig.level = 0.05,
                                    type = "two.sample", alternative = "two.sided")
print(potencia_integrador)

# 4. Simulación de variable categórica "asistencia"
# Suponemos que la probabilidad de alta asistencia varía según el grupo.
asistencia_A <- sample(c("Alta", "Baja"), size = 100, replace = TRUE, prob = c(0.8, 0.2))
asistencia_B <- sample(c("Alta", "Baja"), size = 100, replace = TRUE, prob = c(0.6, 0.4))
grupo <- rep(c("A", "B"), each = 100)
asistencia <- c(asistencia_A, asistencia_B)
datos_integrador <- data.frame(grupo, asistencia)

# Tabla de contingencia y test de independencia
tabla_integrador <- table(datos_integrador$grupo, datos_integrador$asistencia)
print(tabla_integrador)
test_integrador <- chisq.test(tabla_integrador)
print(test_integrador)

library(ggplot2)

# Create the stacked bar chart
ggplot(datos_integrador, aes(x = grupo, fill = asistencia)) +
  geom_bar(position = "fill") +  # "fill" makes it proportional
  labs(title = "Distribución de Asistencia por Grupo de Estudio",
       x = "Grupo de Estudio",
       y = "Proporción",
       fill = "Asistencia") +
  theme_minimal()

```

*Comentario:*  
- Se evalúa si existe diferencia significativa en las notas entre ambos grupos y se calcula la potencia del test.  
- Posteriormente, se analiza si la variable “asistencia” se asocia al grupo de estudio, interpretándose el p‑valor del test chi-cuadrado.

A continuación se presenta una clase completa y detallada en la que primero se introducen todos los conceptos y ejemplos prácticos (usando datasets reales cuando es posible y visualizaciones con ggplot2) sobre:

1. Bootstrapping para variables cualitativas (proporciones)  
2. Test de permutaciones para variables cualitativas (proporciones)  
3. Test de homogeneidad  
4. Test exacto de Fisher  
5. Test de homocedasticidad  
6. Test de normalidad  

Luego se incluye una sección de ejercicios (al menos uno por tema y un ejercicio integrador) y, finalmente, la sección de resoluciones de cada ejercicio.




El **bootstrapping** es un método de remuestreo que permite estimar la distribución de una estadística (por ejemplo, la proporción) al generar muchas muestras “bootstrap” (con reemplazo) a partir de la muestra original. En variables cualitativas, se utiliza para estimar la proporción de un determinado nivel (por ejemplo, la proporción de “Sí”) y para obtener intervalos de confianza sin depender de distribuciones teóricas.

### Ejemplo Práctico

Simulamos una muestra de 100 respuestas (niveles: “Sí” y “No”) y calculamos la proporción de “Sí”. Luego generamos 1000 réplicas para obtener el intervalo de confianza al 95% y visualizamos la distribución.

```{r}
set.seed(123)
# Simulación de 100 respuestas con probabilidad 0.65 de "Sí"
respuestas <- sample(c("Sí", "No"), size = 100, replace = TRUE, prob = c(0.65, 0.35))
prop_original <- mean(respuestas == "Sí")
cat("Proporción original de 'Sí':", round(prop_original, 2), "\n")

# Bootstrapping: 1000 réplicas
n_boot <- 1000
boot_prop <- replicate(n_boot, {
  muestra_boot <- sample(respuestas, size = length(respuestas), replace = TRUE)
  mean(muestra_boot == "Sí")
})

# Intervalo de confianza al 95%
CI <- quantile(boot_prop, probs = c(0.025, 0.975))
cat("Intervalo de confianza 95%:", round(CI[1],2), "-", round(CI[2],2), "\n")

# Visualización con ggplot2
library(ggplot2)
df_boot <- data.frame(prop = boot_prop)
ggplot(df_boot, aes(x = prop)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = CI, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Distribución Bootstrapping de la Proporción de 'Sí'",
       x = "Proporción", y = "Frecuencia") +
  theme_minimal()
```



## 2. Test de Permutaciones para Variables Cualitativas (Proporciones)

### Concepto y Uso

El **test de permutaciones** es un método no paramétrico que consiste en reordenar aleatoriamente las etiquetas de grupo para evaluar la significancia de la diferencia observada en la proporción entre dos grupos.  
- **Proceso:**  
  1. Calcular la diferencia observada en la proporción entre dos grupos.  
  2. Permutar (reordenar) las etiquetas muchas veces y calcular la diferencia en cada permutación.  
  3. Estimar el p‑valor como la proporción de permutaciones en las que la diferencia es al menos tan extrema como la observada.

### Ejemplo Práctico

Simulamos dos grupos de 80 observaciones cada uno, donde en el Grupo A la proporción de “Sí” es 0.70 y en el Grupo B es 0.55. Se evalúa si la diferencia es significativa mediante 5000 permutaciones.

```{r}
set.seed(456)
n <- 80
grupo <- rep(c("A", "B"), each = n)
respuesta <- c(
  sample(c("Sí", "No"), size = n, replace = TRUE, prob = c(0.70, 0.30)),
  sample(c("Sí", "No"), size = n, replace = TRUE, prob = c(0.55, 0.45))
)
datos_perm <- data.frame(grupo, respuesta)

# Diferencia observada en la proporción de "Sí"
prop_A <- mean(datos_perm$respuesta[datos_perm$grupo == "A"] == "Sí")
prop_B <- mean(datos_perm$respuesta[datos_perm$grupo == "B"] == "Sí")
diff_obs <- prop_A - prop_B
cat("Diferencia observada (A - B):", round(diff_obs, 3), "\n")

# Permutaciones: 5000 réplicas
n_perm <- 5000
dif_perm <- replicate(n_perm, {
  grupo_perm <- sample(datos_perm$grupo)
  prop_A_perm <- mean(datos_perm$respuesta[grupo_perm == "A"] == "Sí")
  prop_B_perm <- mean(datos_perm$respuesta[grupo_perm == "B"] == "Sí")
  prop_A_perm - prop_B_perm
})

# p-valor (test bilateral)
p_valor_perm <- mean(abs(dif_perm) >= abs(diff_obs))
cat("p-valor de permutación:", round(p_valor_perm, 4), "\n")

# Visualización de la distribución de diferencias
df_perm <- data.frame(diff = dif_perm)
ggplot(df_perm, aes(x = diff)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
  geom_vline(xintercept = diff_obs, color = "red", linetype = "dashed", size = 1.2) +
  labs(title = "Distribución de Diferencias en Proporciones (Permutaciones)",
       x = "Diferencia (Grupo A - Grupo B)", y = "Frecuencia") +
  theme_minimal()
```



## 3. Test de Homogeneidad

### Concepto y Uso

El **test de homogeneidad** se utiliza para determinar si la distribución de una variable categórica es la misma en distintos grupos.  
- **Hipótesis:**  
  - H₀: Las proporciones de las categorías son iguales en todos los grupos.  
  - H₁: Al menos uno de los grupos presenta una distribución diferente.  
- **Método:** Se usa el test chi-cuadrado aplicado a una tabla de contingencia.

### Ejemplo Práctico

Utilizaremos el dataset *iris*. Creamos una variable a partir de *Sepal.Width*:
- "Ancho" si el valor es mayor o igual a la mediana.  
- "Estrecho" si es menor que la mediana.

Luego evaluamos si la distribución de esta variable es homogénea entre las especies.

```{r}
set.seed(789)
data(iris)
# Crear variable categórica "Ancho_Sepal"
iris$Ancho_Sepal <- ifelse(iris$Sepal.Width >= median(iris$Sepal.Width), "Ancho", "Estrecho")

# Tabla de contingencia
tabla_homo <- table(iris$Species, iris$Ancho_Sepal)
print(tabla_homo)

# Test de homogeneidad (chi-cuadrado)
test_homo <- chisq.test(tabla_homo)
print(test_homo)

# Visualización: gráfico de barras apiladas
ggplot(iris, aes(x = Species, fill = Ancho_Sepal)) +
  geom_bar(position = "fill") +
  labs(title = "Proporción de 'Ancho' vs. 'Estrecho' según Species",
       x = "Species", y = "Proporción") +
  theme_minimal()
```



## 4. Test Exacto de Fisher

### Concepto y Uso

El **test exacto de Fisher** es utilizado para evaluar la asociación en tablas de contingencia 2×2 cuando las frecuencias son bajas.  
- **Hipótesis:**  
  - H₀: No existe asociación entre las dos variables.  
  - H₁: Existe asociación.
- **Ventaja:** Es exacto y no depende de aproximaciones asintóticas.

### Ejemplo Práctico

Se simula una tabla 2×2 con datos pequeños, por ejemplo, para evaluar la asociación entre “Tratamiento” (Sí/No) y “Respuesta” (Éxito/Fracaso).

```{r}
# Crear tabla 2×2
tabla_fisher <- matrix(c(8, 2, 1, 9), nrow = 2,
                       dimnames = list(Tratamiento = c("Sí", "No"),
                                       Respuesta = c("Éxito", "Fracaso")))
print(tabla_fisher)

# Test exacto de Fisher
test_fisher <- fisher.test(tabla_fisher)
print(test_fisher)
```



## 5. Test de Homocedasticidad

### Concepto y Uso

El test de homocedasticidad evalúa si la varianza de los datos es la misma en distintos grupos, lo cual es un supuesto fundamental en muchos tests paramétricos.  
- **Métodos comunes:**  
  - Test de Bartlett (más sensible a la normalidad).  
  - Test de Levene (más robusto).

### Ejemplo Práctico

Utilizaremos el dataset *iris* para evaluar si la varianza de *Sepal.Length* es homogénea entre las especies mediante el test de Bartlett.

```{r}
# Test de homocedasticidad con Bartlett
bartlett_result <- bartlett.test(Sepal.Length ~ Species, data = iris)
print(bartlett_result)

# Visualización: Boxplot de Sepal.Length por Species
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Boxplot de Sepal.Length por Species",
       x = "Species", y = "Sepal.Length") +
  theme_minimal()
```


## 6. Test de Normalidad

### Concepto y Uso

El test de normalidad se utiliza para evaluar si una variable sigue una distribución normal, lo que es importante para muchos análisis paramétricos.  
- **Test común:** Shapiro-Wilk.  
- **Complemento visual:** Q-Q plot y histogramas.

### Ejemplo Práctico

Aplicamos el test de Shapiro-Wilk a la variable *Sepal.Length* del dataset *iris* y generamos un Q-Q plot para visualizar la normalidad.

```{r}
# Test de Shapiro-Wilk para Sepal.Length
shapiro_result <- shapiro.test(iris$Sepal.Length)
print(shapiro_result)

# Q-Q plot con ggplot2
ggplot(iris, aes(sample = Sepal.Length)) +
  stat_qq(color = "blue") +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot de Sepal.Length",
       x = "Cuantiles teóricos", y = "Cuantiles muestrales") +
  theme_minimal()
```


### Test Anderson-Darling
El test de Anderson-Darling es una prueba estadística que evalúa si un conjunto de datos sigue una distribución teórica, en este caso, la distribución normal. A diferencia del test de Shapiro-Wilk, este test pone mayor énfasis en las colas de la distribución, lo que lo hace especialmente sensible a desviaciones en los extremos. El método se basa en comparar la función de distribución empírica de la muestra con la función de distribución teórica esperada. El estadístico del test se calcula a partir de la suma ponderada de las diferencias entre ambas funciones. Un valor alto del estadístico indica una discrepancia significativa, sugiriendo que los datos pueden no seguir una distribución normal

```{r}
# Cargar el paquete nortest (instalar si es necesario)
if (!require(nortest)) {
  install.packages("nortest")
  library(nortest)
}

# Test de Anderson-Darling para Sepal.Length
ad_result <- ad.test(iris$Sepal.Length)
print(ad_result)


ggplot(iris, aes(x = Sepal.Length)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(iris$Sepal.Length), sd = sd(iris$Sepal.Length)), 
                color = "red", size = 1) +
  labs(title = "Histograma de Sepal.Length con curva normal",
       x = "Sepal.Length", y = "Densidad") +
  theme_minimal()

```

```{r}

normal_real <- rnorm(200, mean = 15, sd = 3)

ad_result2 <- ad.test(normal_real)
print(ad_result2)

df <- data.frame(normal_real)

ggplot(df, aes(x = normal_real)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightgreen", color = "black") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(normal_real), sd = sd(normal_real)), 
                color = "blue", size = 1) +
  labs(title = "Histograma con curva normal",
       x = "Valor", y = "Densidad") +
  theme_minimal()


```

# Sección de Ejercicios

### Ejercicio 1: Bootstrapping para Proporciones
  
Simule una muestra de 150 observaciones de una variable categórica con niveles “Aprobado” y “Reprobado” donde la probabilidad de “Aprobado” sea 0.70.  
- Calcule la proporción original de “Aprobado”.  
- Realice 2000 réplicas de bootstrapping para estimar dicha proporción.  
- Obtenga el intervalo de confianza al 95% y grafique la distribución de las proporciones obtenidas.



### Ejercicio 2: Test de Permutaciones para Proporciones
  
Simule dos grupos con 100 observaciones cada uno.  
- En el Grupo 1, la proporción de “Aprobado” es 0.80; en el Grupo 2, es 0.65.  
- Realice un test de permutaciones con 3000 réplicas para evaluar si la diferencia en proporciones es significativa.  
- Grafique la distribución de las diferencias permutadas y reporte el p‑valor.



### Ejercicio 3: Test de Homogeneidad
  
Utilice datos simulados para tres regiones donde se clasifica la preferencia de un producto en tres niveles: Alta, Media y Baja.  
- Construya la tabla de contingencia.  
- Realice el test de homogeneidad (chi-cuadrado) para evaluar si la distribución de preferencias es similar entre las regiones.  
- Interprete el p‑valor.



### Ejercicio 4: Test Exacto de Fisher
  
Simule una tabla 2×2 con datos pequeños para las variables “Uso de medicamento” (Sí/No) y “Recuperación” (Mejora/No mejora) con un total de 20 observaciones.  
- Realice el test exacto de Fisher.  
- Interprete el p‑valor y concluya sobre la asociación.



### Ejercicio 5: Test de Homocedasticidad
  
Utilice el dataset *iris* o simule tres grupos de datos numéricos.  
- Realice un test de homocedasticidad (puede usar el test de Bartlett) para evaluar si las varianzas son iguales entre los grupos.  
- Reporte el p‑valor y concluya si se cumple el supuesto de igualdad de varianzas.



### Ejercicio 6: Test de Normalidad
  
Utilice la variable *mpg* del dataset *mtcars*.  
- Realice el test de normalidad utilizando el test de Shapiro-Wilk.  
- Genere un Q-Q plot para visualizar la normalidad.  
- Interprete los resultados.



### Ejercicio Integrador
  
Utilizando el dataset *iris* y simulaciones, realice lo siguiente:
1. Cree una variable categórica “Ancho_Sepal” a partir de *Sepal.Width* (defina “Ancho” si el valor es mayor o igual a la mediana y “Estrecho” si es menor).
2. Realice un test de homogeneidad para evaluar si la distribución de “Ancho_Sepal” es la misma entre las tres especies.
3. Realice un test de normalidad sobre la variable *Sepal.Length*.
4. Realice un test de homocedasticidad para comparar la varianza de *Sepal.Length* entre las especies.
5. Presente visualizaciones: gráfico de barras para “Ancho_Sepal” por especie, Q-Q plot para *Sepal.Length* y boxplots de *Sepal.Length* por especie.



# Sección de Resoluciones

## Resolución Ejercicio 1: Bootstrapping para Proporciones

```{r}
set.seed(101)
# Simulación de 150 observaciones con probabilidad 0.70 para "Aprobado"
resultados <- sample(c("Aprobado", "Reprobado"), size = 150, replace = TRUE, prob = c(0.70, 0.30))
prop_original <- mean(resultados == "Aprobado")
cat("Proporción original de 'Aprobado':", round(prop_original, 2), "\n")

# Bootstrapping: 2000 réplicas
n_boot <- 2000
boot_prop <- replicate(n_boot, {
  muestra_boot <- sample(resultados, size = length(resultados), replace = TRUE)
  mean(muestra_boot == "Aprobado")
})
CI <- quantile(boot_prop, probs = c(0.025, 0.975))
cat("Intervalo de confianza 95%:", round(CI[1],2), "-", round(CI[2],2), "\n")

# Gráfica
library(ggplot2)
df_boot <- data.frame(prop = boot_prop)
ggplot(df_boot, aes(x = prop)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = CI, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Bootstrapping: Proporción de 'Aprobado'",
       x = "Proporción", y = "Frecuencia") +
  theme_minimal()
```



## Resolución Ejercicio 2: Test de Permutaciones para Proporciones

```{r}
set.seed(202)
n <- 100
grupo <- rep(c("Grupo1", "Grupo2"), each = n)
datos <- data.frame(grupo, 
                    resultado = c(
                      sample(c("Aprobado", "Reprobado"), n, replace = TRUE, prob = c(0.80, 0.20)),
                      sample(c("Aprobado", "Reprobado"), n, replace = TRUE, prob = c(0.65, 0.35))
                    ))
prop_g1 <- mean(datos$resultado[datos$grupo == "Grupo1"] == "Aprobado")
prop_g2 <- mean(datos$resultado[datos$grupo == "Grupo2"] == "Aprobado")
diff_obs <- prop_g1 - prop_g2
cat("Diferencia observada (Grupo1 - Grupo2):", round(diff_obs, 3), "\n")

# Permutación: 3000 réplicas
n_perm <- 3000
dif_perm <- replicate(n_perm, {
  grupo_perm <- sample(datos$grupo)
  p1 <- mean(datos$resultado[grupo_perm == "Grupo1"] == "Aprobado")
  p2 <- mean(datos$resultado[grupo_perm == "Grupo2"] == "Aprobado")
  p1 - p2
})
p_valor_perm <- mean(abs(dif_perm) >= abs(diff_obs))
cat("p-valor (permutación):", round(p_valor_perm, 4), "\n")

# Gráfica
df_perm <- data.frame(diff = dif_perm)
ggplot(df_perm, aes(x = diff)) +
  geom_histogram(bins = 30, fill = "lightgreen", color = "black", alpha = 0.7) +
  geom_vline(xintercept = diff_obs, color = "red", linetype = "dashed", size = 1.2) +
  labs(title = "Permutación: Diferencia en Proporciones",
       x = "Diferencia (Grupo1 - Grupo2)", y = "Frecuencia") +
  theme_minimal()
```



## Resolución Ejercicio 3: Test de Homogeneidad

```{r}
set.seed(303)
# Simulación para tres regiones con tres niveles de preferencia
region <- rep(c("Región1", "Región2", "Región3"), each = 100)
preferencia <- sample(c("Alta", "Media", "Baja"), size = 300, replace = TRUE,
                       prob = c(0.5, 0.3, 0.2))
datos_homo <- data.frame(region, preferencia)
tabla <- table(datos_homo$region, datos_homo$preferencia)
print(tabla)

# Test de homogeneidad (chi-cuadrado)
test_homo <- chisq.test(tabla)
print(test_homo)
```



## Resolución Ejercicio 4: Test Exacto de Fisher

```{r}
# Simulación de una tabla 2x2 con 20 observaciones totales
tabla_f <- matrix(c(4, 3, 2, 5), nrow = 2,
                  dimnames = list("Uso_Medicamento" = c("Sí", "No"),
                                  "Recuperación" = c("Mejora", "No mejora")))
print(tabla_f)
# Test exacto de Fisher
test_fisher <- fisher.test(tabla_f)
print(test_fisher)
```



## Resolución Ejercicio 5: Test de Homocedasticidad

```{r}
# Utilizando el dataset iris
data(iris)
# Test de homocedasticidad con Bartlett
test_bartlett <- bartlett.test(Sepal.Length ~ Species, data = iris)
print(test_bartlett)

# Visualización: Boxplot
library(ggplot2)
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Boxplot: Sepal.Length por Species",
       x = "Species", y = "Sepal.Length") +
  theme_minimal()
```



## Resolución Ejercicio 6: Test de Normalidad

```{r}
# Utilizando la variable mpg del dataset mtcars
data(mtcars)
test_shapiro <- shapiro.test(mtcars$mpg)
print(test_shapiro)

# Q-Q plot
ggplot(mtcars, aes(sample = mpg)) +
  stat_qq(color = "blue") +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot de mpg", x = "Cuantiles teóricos", y = "Cuantiles muestrales") +
  theme_minimal()
```



## Resolución Ejercicio Integrador

```{r}
# Utilizando el dataset iris
data(iris)
# 1. Crear variable categórica "Ancho_Sepal" a partir de Sepal.Width
iris$Ancho_Sepal <- ifelse(iris$Sepal.Width >= median(iris$Sepal.Width), "Ancho", "Estrecho")
tabla_integrador <- table(iris$Species, iris$Ancho_Sepal)
cat("Tabla de contingencia (Species vs. Ancho_Sepal):\n")
print(tabla_integrador)

# 2. Test de homogeneidad para Ancho_Sepal
test_homogeneidad <- chisq.test(tabla_integrador)
print(test_homogeneidad)

# Visualización: gráfico de barras
ggplot(iris, aes(x = Species, fill = Ancho_Sepal)) +
  geom_bar(position = "fill") +
  labs(title = "Distribución de 'Ancho_Sepal' por Species",
       x = "Species", y = "Proporción") +
  theme_minimal()

# 3. Test de normalidad para Sepal.Length
test_normalidad <- shapiro.test(iris$Sepal.Length)
print(test_normalidad)

# Q-Q plot para Sepal.Length
ggplot(iris, aes(sample = Sepal.Length)) +
  stat_qq(color = "blue") +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot de Sepal.Length",
       x = "Cuantiles teóricos", y = "Cuantiles muestrales") +
  theme_minimal()

# 4. Test de homocedasticidad para Sepal.Length entre Species (usando Bartlett)
test_homocedasticidad <- bartlett.test(Sepal.Length ~ Species, data = iris)
print(test_homocedasticidad)

# Visualización: Boxplot de Sepal.Length por Species
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Boxplot de Sepal.Length por Species",
       x = "Species", y = "Sepal.Length") +
  theme_minimal()
```


## Test de Independencia

El **test de independencia** se utiliza para determinar si dos variables categóricas están asociadas o si son independientes. Esto se logra mediante el análisis de una tabla de contingencia que resume las frecuencias observadas en cada combinación de categorías y, a partir de ella, se calcula la estadística chi-cuadrado.

### ¿Cómo Funciona?

1. **Construcción de la Tabla de Contingencia:**  
   Se cuentan las ocurrencias de cada combinación de categorías. Por ejemplo, en el dataset *iris*, podemos crear una variable categórica a partir de *Sepal.Width*:
   - Se define "Ancho" si el valor es mayor o igual a la mediana.
   - Se define "Estrecho" si es menor que la mediana.

2. **Cálculo de la Estadística Chi-cuadrado:**  
   Se comparan las frecuencias observadas con las esperadas (suponiendo independencia). La estadística resultante evalúa la discrepancia entre ambas; un valor alto (con p‑valor pequeño) indica que es poco probable que las diferencias se deban al azar, lo que sugiere que las variables no son independientes.

3. **Interpretación del p‑valor:**  
   - **p‑valor < 0.05:** Se rechaza la hipótesis nula de independencia y se concluye que existe asociación entre las variables.  
   - **p‑valor ≥ 0.05:** No se rechaza la hipótesis nula, sugiriendo que no hay evidencia suficiente para afirmar que las variables están asociadas.

### Ejemplo Práctico con el Dataset *iris*

En este ejemplo, se crea la variable categórica **Ancho_Sepal** a partir de *Sepal.Width* y se evalúa si existe asociación entre **Species** y **Ancho_Sepal**.

```{r}
# Utilizando el dataset iris
data(iris)

# Crear variable categórica "Ancho_Sepal" a partir de Sepal.Width:
# "Ancho" si el valor es mayor o igual a la mediana, "Estrecho" si es menor.
iris$Ancho_Sepal <- ifelse(iris$Sepal.Width >= median(iris$Sepal.Width), "Ancho", "Estrecho")

# Construcción de la tabla de contingencia
tabla_indep <- table(iris$Species, iris$Ancho_Sepal)
print(tabla_indep)

# Realización del test de independencia (chi-cuadrado)
test_indep <- chisq.test(tabla_indep)
print(test_indep)
```

### Visualización con ggplot2

La siguiente gráfica muestra la proporción de observaciones en cada categoría de **Ancho_Sepal** para cada **Species**. La visualización facilita la interpretación de la distribución de las frecuencias.

```{r}
library(ggplot2)
ggplot(iris, aes(x = Species, fill = Ancho_Sepal)) +
  geom_bar(position = "fill") +
  labs(title = "Proporción de 'Ancho_Sepal' según Species",
       x = "Especie",
       y = "Proporción",
       fill = "Ancho_Sepal") +
  theme_minimal()
```



## Ejercicio Test de independencia

  
Simule un dataset de 200 observaciones con dos variables categóricas:  
- **Color:** con niveles "Rojo" y "Verde" (donde la probabilidad de "Rojo" es 60% y "Verde" 40%).  
- **Aprobación:** con niveles "Sí" y "No".  
  - Para las observaciones de color "Rojo", la probabilidad de "Sí" es 55% y de "No" 45%.  
  - Para las observaciones de color "Verde", la probabilidad de "Sí" es 50% y de "No" 50%.  

Realice un test de independencia para evaluar si existe relación entre el **Color** y la **Aprobación** y visualice la distribución de las proporciones.

## Ejercicio Bonus

Hagan lo mismo pero en vez de tamaño de muestra fijo en 200, para cada posible tamaño de muestra entre 100 y 4000 (intervalos cada 100), y visualizenlo con el eje x el tamaño de la muestra y en el eje y el p-valor obtenido en el test.



### Resolución del Ejercicio

```{r}
set.seed(123)
# Generar la variable "Color" con 200 observaciones
color <- sample(c("Rojo", "Verde"), size = 200, replace = TRUE, prob = c(0.6, 0.4))

# Generar la variable "Aprobación" dependiendo del valor de "Color"
aprobacion <- sapply(color, function(x) {
  if (x == "Rojo") {
    sample(c("Sí", "No"), size = 1, prob = c(0.55, 0.45))
  } else {
    sample(c("Sí", "No"), size = 1, prob = c(0.5, 0.5))
  }
})

# Crear el dataframe
datos <- data.frame(Color = color, Aprobacion = aprobacion)

# Construcción de la tabla de contingencia
tabla_ej <- table(datos$Color, datos$Aprobacion)
print(tabla_ej)

# Realización del test de independencia
test_ej <- chisq.test(tabla_ej)
print(test_ej)

# Visualización de la distribución de las proporciones con ggplot2
ggplot(datos, aes(x = Color, fill = Aprobacion)) +
  geom_bar(position = "fill") +
  labs(title = "Proporción de Aprobación según Color",
       x = "Color",
       y = "Proporción",
       fill = "Aprobación") +
  theme_minimal()
```
## Resolucion ejercicio bonus

```{r}
set.seed(123)
library(ggplot2)

# Definir una secuencia de tamaños de muestra de 5 a 400 (pasos de 5)
tamanos <- seq(100, 4000, by = 100)

# Función para simular el dataset y obtener el p-valor del test de independencia
obtener_pvalor <- function(n) {
  # Simular la variable "Color"
  color <- sample(c("Rojo", "Verde"), size = n, replace = TRUE, prob = c(0.6, 0.4))
  
  # Generar la variable "Aprobacion" en función de "Color"
  aprobacion <- sapply(color, function(x) {
    if(x == "Rojo") {
      sample(c("Sí", "No"), size = 1, prob = c(0.55, 0.45))
    } else {
      sample(c("Sí", "No"), size = 1, prob = c(0.5, 0.5))
    }
  })
  
  datos_temp <- data.frame(Color = color, Aprobacion = aprobacion)
  
  # Construir la tabla de contingencia. Si falta alguna categoría (por ejemplo, en muestras muy pequeñas),
  # se rellena con 0 para mantener las dimensiones.
  tabla <- with(datos_temp, table(factor(Color, levels = c("Rojo", "Verde")),
                                  factor(Aprobacion, levels = c("Sí", "No"))))
  
  # Para tamaños muy pequeños puede ocurrir que no haya suficiente información, por lo que se usa NA
  if(any(dim(tabla) < 2) || any(tabla == 0)) {
    p_val <- NA
  } else {
    p_val <- chisq.test(tabla)$p.value
  }
  
  return(p_val)
}

# Aplicar la función a cada tamaño de muestra
p_valores <- sapply(tamanos, obtener_pvalor)

# Crear dataframe para la visualización
df_p <- data.frame(Tamano = tamanos, p_valor = p_valores)

# Graficar el p-valor en función del tamaño de la muestra
ggplot(df_p, aes(x = Tamano, y = p_valor)) +
  geom_line(color = "darkblue") +
  geom_point(color = "darkblue") +
  geom_hline(yintercept = 0.05, linetype = "dashed", color = "red") +  # Línea de rechazo
  labs(title = "Cambio del p-valor en función del tamaño de la muestra",
       x = "Tamaño de la muestra",
       y = "p-valor") +
  theme_minimal()


```

