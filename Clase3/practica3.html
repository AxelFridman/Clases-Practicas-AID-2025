<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Practica 3 AID 2025</title>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="section-header">



<h1 class="title toc-ignore">Practica 3 AID 2025</h1>

</div>


<div id="section-conceptos-básicos-de-un-test-de-hipótesis"
class="section level1">
<h1>1. Conceptos Básicos de un Test de Hipótesis</h1>
<div id="section-hipótesis-nula-h₀-y-alternativa-h₁"
class="section level2">
<h2>1.1. Hipótesis Nula (H₀) y Alternativa (H₁)</h2>
<p>Un <strong>test de hipótesis</strong> es un procedimiento estadístico
para tomar decisiones sobre una afirmación (hipótesis) acerca de una
característica de la población.</p>
<ul>
<li><strong>Hipótesis nula (H₀):</strong> Generalmente plantea “no
existe efecto” o “no hay diferencia”.<br />
</li>
<li><strong>Hipótesis alternativa (H₁):</strong> Plantea lo contrario,
es decir, que sí existe efecto o diferencia.</li>
</ul>
</div>
<div id="section-errores-de-tipo-i-y-tipo-ii" class="section level2">
<h2>1.2. Errores de Tipo I y Tipo II</h2>
<ul>
<li><p><strong>Error Tipo I (<span
class="math inline">\(\alpha\)</span>)</strong><br />
Se comete cuando <strong>rechazamos H₀</strong> siendo ésta
<strong>verdadera</strong>.Se llama “falso positivo”.<br />
<span class="math display">\[
  \alpha = P(\text{rechazar H₀} \mid H₀ \text{ es verdadera}).
\]</span></p></li>
<li><p><strong>Error Tipo II (<span
class="math inline">\(\beta\)</span>)</strong><br />
Ocurre cuando <strong>no se rechaza H₀</strong> siendo ésta
<strong>falsa</strong>. Se le llama “falso negativo”.<br />
<span class="math display">\[
  \beta = P(\text{no rechazar H₀} \mid H₀ \text{ es falsa}).
\]</span></p></li>
</ul>
</div>
<div id="section-nivel-de-significación-y-potencia"
class="section level2">
<h2>1.3. Nivel de Significación y Potencia</h2>
<ul>
<li><strong>Nivel de significación (<span
class="math inline">\(\alpha\)</span>):</strong><br />
Es la probabilidad máxima que aceptamos para cometer un Error Tipo I.
Usualmente se fija en 0.05 o 0.01.<br />
</li>
<li><strong>Potencia de la prueba (<span
class="math inline">\(1-\beta\)</span>):</strong><br />
Es la probabilidad de <strong>rechazar H₀</strong> cuando realmente es
falsa. Cuanto más alta sea la potencia, más sensible es el test para
detectar efectos reales.</li>
</ul>
<p><span class="math display">\[
    1 - \beta = P(\text{rechazar H₀} \mid H₀ \text{ es falsa}).
\]</span></p>
</div>
</div>
<div id="section-relación-entre-alpha-beta-y-tamaño-de-la-muestra"
class="section level1">
<h1>2. Relación entre <span class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\beta\)</span> y Tamaño de la Muestra</h1>
<div
id="section-relación-entre-alpha-beta-tamaño-muestral-y-tamaño-del-efecto-mínimo-relevante"
class="section level2">
<h2>Relación entre <span class="math inline">\(\alpha\)</span>, <span
class="math inline">\(\beta\)</span>, tamaño muestral y tamaño del
efecto mínimo relevante</h2>
<p>Al diseñar un test estadístico, es importante entender cómo se
relacionan cuatro elementos clave:</p>
<ul>
<li><strong><span class="math inline">\(\alpha\)</span></strong>: Nivel
de significancia (probabilidad de error tipo I)</li>
<li><strong><span class="math inline">\(\beta\)</span></strong>:
Probabilidad de error tipo II</li>
<li><strong>Potencia</strong>: <span class="math inline">\(1 -
\beta\)</span>, es decir, la probabilidad de detectar un efecto
real</li>
<li><strong>Tamaño del efecto mínimo relevante</strong> (<span
class="math inline">\(\Delta\)</span>): La diferencia entre grupos o
condiciones que consideramos importante desde el punto de vista
práctico</li>
</ul>
<hr />
<div id="section-qué-es-el-tamaño-del-efecto-mínimo-relevante"
class="section level3">
<h3>1. ¿Qué es el tamaño del efecto mínimo relevante?</h3>
<p>Es la <strong>magnitud mínima del efecto</strong> que nos interesa
detectar. No es cualquier diferencia, sino una que tenga sentido
práctico, clínico o industrial.</p>
<ul>
<li>En un estudio médico: una reducción de al menos 5 mmHg en la
presión</li>
<li>En educación: una mejora de 1 punto en un examen</li>
<li>En producción: una diferencia de 0.5 mm en una pieza mecánica</li>
</ul>
<p>Este valor lo <strong>define el investigador</strong>, y es necesario
para calcular el tamaño de muestra o la potencia.</p>
<hr />
</div>
<div id="section-relación-entre-los-parámetros" class="section level3">
<h3>2. Relación entre los parámetros</h3>
<div id="section-para-un-nivel-de-significación-alpha-dado"
class="section level4">
<h4>Para un nivel de significación <span
class="math inline">\(\alpha\)</span> dado:</h4>
<ul>
<li>Al <strong>aumentar</strong> el tamaño muestral <span
class="math inline">\(n\)</span>, <strong>disminuye</strong> <span
class="math inline">\(\beta\)</span></li>
<li>Esto significa que <strong>aumenta</strong> la
<strong>potencia</strong> (<span class="math inline">\(1 -
\beta\)</span>)</li>
</ul>
</div>
<div id="section-para-un-tamaño-de-muestra-fijo" class="section level4">
<h4>Para un tamaño de muestra fijo:</h4>
<ul>
<li>Al <strong>disminuir</strong> <span
class="math inline">\(\alpha\)</span>, <strong>aumenta</strong> <span
class="math inline">\(\beta\)</span></li>
<li>Al <strong>aumentar</strong> <span
class="math inline">\(\alpha\)</span>, <strong>disminuye</strong> <span
class="math inline">\(\beta\)</span></li>
</ul>
</div>
<div id="section-para-alpha-y-n-fijos" class="section level4">
<h4>Para <span class="math inline">\(\alpha\)</span> y <span
class="math inline">\(n\)</span> fijos:</h4>
<ul>
<li>Cuanto más grande sea el <strong>tamaño del efecto mínimo
relevante</strong> (<span class="math inline">\(\Delta\)</span>),
<strong>más fácil es detectarlo</strong></li>
<li>A medida que el efecto que queremos detectar se
<strong>reduce</strong>, se necesita un <strong>n mayor</strong> para
mantener la misma potencia</li>
</ul>
<hr />
</div>
</div>
<div id="section-diseño-de-un-test-qué-se-fija-y-qué-se-calcula"
class="section level3">
<h3>3. Diseño de un test: ¿Qué se fija y qué se calcula?</h3>
<table>
<colgroup>
<col width="36%" />
<col width="27%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th>Parámetro</th>
<th>¿Se puede fijar?</th>
<th>¿Normalmente se fija?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Nivel de significancia (<span
class="math inline">\(\alpha\)</span>)</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="even">
<td>Potencia deseada (<span class="math inline">\(1 -
\beta\)</span>)</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="odd">
<td>Tamaño del efecto relevante (<span
class="math inline">\(\Delta\)</span>)</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr class="even">
<td>Tamaño de muestra (<span class="math inline">\(n\)</span>)</td>
<td>✅</td>
<td>✅ (si estás diseñando el experimento)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div
id="section-curvas-de-beta-operación-característica-y-1-beta-potencia"
class="section level1">
<h1>3. Curvas de <span class="math inline">\(\beta\)</span> (Operación
Característica) y <span class="math inline">\(1-\beta\)</span>
(Potencia)</h1>
<ul>
<li><strong>Curva de Operación Característica (COC):</strong> Muestra
cómo evoluciona <span class="math inline">\(\beta\)</span> (probabilidad
de no rechazar H₀ cuando es falsa) frente a cambios en parámetros como
el tamaño de la muestra, el efecto o <span
class="math inline">\(\alpha\)</span>.<br />
</li>
<li><strong>Curva de Potencia:</strong> Muestra <span
class="math inline">\(1 - \beta\)</span>, la probabilidad de rechazar H₀
correctamente cuando es falsa, según el mismo tipo de variaciones.</li>
</ul>
<p>Ambas curvas son importantes para planificar estudios:<br />
- La <strong>Curva de Potencia</strong> ayuda a decidir cuán grande debe
ser la muestra para detectar un efecto de cierto tamaño con la
probabilidad deseada.<br />
- La <strong>COC</strong> puede usarse también como referencia para ver
la probabilidad de cometer un falso negativo en distintos
escenarios.</p>
<blockquote>
<p><strong>Supuestos para simplificar</strong>:<br />
- Prueba de hipótesis a dos colas para una media, con desviación
estándar conocida igual a 1.<br />
- H₀: <span class="math inline">\(\mu = 0\)</span>.<br />
- H₁: <span class="math inline">\(\mu \neq 0\)</span>.<br />
- El “efecto” real (verdadera media <span
class="math inline">\(\mu\)</span>) se asume diferente de 0; por
ejemplo, <span class="math inline">\(\mu = 1\)</span>.<br />
- <span class="math inline">\(\alpha\)</span> tomará algunos valores
típicos (0.01, 0.05, 0.1).<br />
- <span class="math inline">\(n\)</span> variará en un rango (por ej., 5
a 100).</p>
</blockquote>
<div id="section-cálculo-de-beta-error-tipo-ii" class="section level2">
<h2>4. Cálculo de <span class="math inline">\(\beta\)</span> (Error Tipo
II)</h2>
<p>Para una prueba de dos colas, se rechaza H₀ si <span
class="math inline">\(\lvert Z \rvert &gt; z_{\alpha/2}\)</span>, donde
<span class="math inline">\(Z \sim \mathcal{N}(\delta,
1)\)</span>.<br />
- <span class="math inline">\(\delta\)</span> es el verdadero
desplazamiento de la media en unidades de error estándar, <span
class="math inline">\(\delta = \frac{\text{(media real - media
hipotética)} \times \sqrt{n}}{\sigma}\)</span>.<br />
- <span class="math inline">\(\beta = P(\text{no rechazar H₀} \mid
\text{H₀ es falsa})\)</span>.<br />
- Entonces, <span class="math inline">\(\beta = P(-z_{\alpha/2} \leq Z
\leq z_{\alpha/2})\)</span>.</p>
<p>Matemáticamente, para <span class="math inline">\(Z \sim
\mathcal{N}(\delta,1)\)</span>: <span class="math display">\[
  \beta = \Phi\bigl(z_{\alpha/2} - \delta\bigr) \;-\;
\Phi\bigl(-z_{\alpha/2} - \delta\bigr).
\]</span></p>
<p>Donde <span class="math inline">\(\Phi\)</span> es la función de
distribución acumulada de la Normal Estándar.</p>
<pre class="r"><code>library(ggplot2)

# Definimos la función para calcular Beta en una prueba de 2 colas:
calc_beta &lt;- function(n, alpha, efecto = 1, sigma = 1) {
  z_alpha_2 &lt;- qnorm(1 - alpha / 2)  # valor crítico
  # delta es el desplazamiento (media real - media hipotética) * sqrt(n)/sigma
  delta &lt;- (efecto * sqrt(n)) / sigma
  
  # Probabilidad de no rechazar H0
  beta_val &lt;- pnorm(z_alpha_2 - delta) - pnorm(-z_alpha_2 - delta)
  return(beta_val)
}

# Distintos valores de alpha
alpha_values &lt;- c(0.01, 0.05, 0.10)
# Rango de tamaños de muestra
n_values &lt;- seq(5, 100, by = 1)

# Construimos un data frame con todas las combinaciones de n y alpha
df_beta &lt;- expand.grid(
  n = n_values,
  alpha = alpha_values
)

# Calculamos Beta para cada combinación
df_beta$Beta &lt;- mapply(
  calc_beta,
  n = df_beta$n,
  alpha = df_beta$alpha
)

# Graficamos Beta vs n, con distintas curvas para cada alpha
ggplot(df_beta, aes(x = n, y = Beta, color = factor(alpha))) +
  geom_line(size = 1) +
  geom_point() +
  labs(
    title = &quot;Curva de Operacion Caracteristica: Beta vs. Tamano muestral&quot;,
    x = &quot;Tamano de la muestra (n)&quot;,
    y = expression(beta),
    color = expression(alpha)
  ) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p><strong>Interpretación del gráfico de Beta (<span
class="math inline">\(\beta\)</span>):</strong><br />
- Para una media real <span class="math inline">\(\mu = 1\)</span>
(efecto de 1 unidad), se observa que a mayor <span
class="math inline">\(n\)</span>, menor <span
class="math inline">\(\beta\)</span>.<br />
- A su vez, para un mismo <span class="math inline">\(n\)</span>,
valores más grandes de <span class="math inline">\(\alpha\)</span>
implican <span class="math inline">\(\beta\)</span> más baja.</p>
</div>
<div id="section-curva-de-potencia-1---beta-vs.-tamaño-de-la-muestra"
class="section level2">
<h2>4.2. Curva de Potencia (<span class="math inline">\(1 -
\beta\)</span>) vs. Tamaño de la Muestra</h2>
<p>La <strong>potencia</strong> es <span class="math inline">\(1 -
\beta\)</span>. Representa la probabilidad de <strong>rechazar
H₀</strong> (correctamente) cuando en realidad hay un efecto. Graficarla
nos muestra qué tan “sensible” es nuestro test con distintos tamaños de
muestra y distintos niveles de significancia.</p>
<pre class="r"><code># Agregamos la columna &quot;Potencia&quot; = 1 - Beta
df_beta$Potencia &lt;- 1 - df_beta$Beta

# Graficamos la Curva de Potencia vs n, para cada alpha
ggplot(df_beta, aes(x = n, y = Potencia, color = factor(alpha))) +
  geom_line(size = 1) +
  geom_point() +
  labs(
    title = &quot;Curva de Potencia: (1 - Beta) vs. Tamano muestral&quot;,
    x = &quot;Tamano de la muestra (n)&quot;,
    y = &quot;Potencia = 1 - Beta&quot;,
    color = expression(alpha)
  ) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p><strong>Interpretación del gráfico de Potencia (<span
class="math inline">\(1 - \beta\)</span>):</strong><br />
- A medida que aumenta <span class="math inline">\(n\)</span>, la
potencia se aproxima a 1 (test más capaz de detectar diferencias
reales).<br />
- Para un mismo <span class="math inline">\(n\)</span>, un <span
class="math inline">\(\alpha\)</span> mayor también eleva la
probabilidad de rechazar H₀, por lo que la potencia aumenta.</p>
<pre class="r"><code>calc_beta &lt;- function(n, alpha, delta, sigma = 1) {
  z_alpha_2 &lt;- qnorm(1 - alpha / 2)
  # delta estandarizado: (delta * sqrt(n)) / sigma
  delta_std &lt;- (delta * sqrt(n)) / sigma
  # Beta = P(-z_alpha_2 &lt;= Z - delta_std &lt;= z_alpha_2) para Z ~ N(0,1)
  beta_val &lt;- pnorm(z_alpha_2 - delta_std) - pnorm(-z_alpha_2 - delta_std)
  return(beta_val)
}

# Parametros fijos y rangos
n_fijo &lt;- 30
alpha_values &lt;- c(0.01, 0.05, 0.10)
delta_values &lt;- seq(-1.5, 1.5, by = 0.005)

df_beta_delta &lt;- expand.grid(delta = delta_values, alpha = alpha_values)

df_beta_delta$Beta &lt;- mapply(
  function(a, d) calc_beta(n_fijo, a, d),
  df_beta_delta$alpha,
  df_beta_delta$delta
)

ggplot(df_beta_delta, aes(x = delta, y = Beta, color = factor(alpha))) +
  geom_line(size = 1) +
  labs(
    title = &quot;Beta vs Delta con n=30&quot;,
    x = &quot;Delta (diferencia)&quot;,
    y = &quot;Beta&quot;,
    color = expression(alpha)
  ) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code># Parametros fijos y rangos
n_fijo &lt;- 300
alpha_values &lt;- c(0.01, 0.05, 0.10)
delta_values &lt;- seq(-1.5, 1.5, by = 0.005)

df_beta_delta &lt;- expand.grid(delta = delta_values, alpha = alpha_values)

df_beta_delta$Beta &lt;- mapply(
  function(a, d) calc_beta(n_fijo, a, d),
  df_beta_delta$alpha,
  df_beta_delta$delta
)

ggplot(df_beta_delta, aes(x = delta, y = Beta, color = factor(alpha))) +
  geom_line(size = 1) +
  labs(
    title = &quot;Beta vs Delta con n=300&quot;,
    x = &quot;Delta (diferencia)&quot;,
    y = &quot;Beta&quot;,
    color = expression(alpha)
  ) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
</div>
<div id="section-ejemplo-de-prueba-de-hipótesis-y-cálculo-de-pvalor"
class="section level1">
<h1>5. Ejemplo de Prueba de Hipótesis y Cálculo de p‑valor</h1>
<ol style="list-style-type: decimal">
<li><strong>p‑valor pequeño (ej. &lt; 0.05):</strong> Evidencia para
rechazar H₀.<br />
</li>
<li><strong>p‑valor grande:</strong> No hay evidencia suficiente para
rechazar H₀.</li>
</ol>
<div id="section-simulación-y-cálculo-del-pvalor-varianza-conocida"
class="section level3">
<h3>5.1.1 Simulación y Cálculo del p‑valor varianza conocida</h3>
<pre class="r"><code>set.seed(100)
sd_poblacional &lt;- 2 # conocido
# Simulamos datos donde la media real es 10.5, sd=2, n=40
muestra &lt;- rnorm(40, mean = 10.5, sd = sd_poblacional)

media_muestra &lt;- mean(muestra)
n &lt;- length(muestra)
media_hipotetica &lt;- 10

# Estadístico z para H0: mu = 10 vs H1: mu != 10
error_estandar &lt;- sd_poblacional / sqrt(n)
z_stat &lt;- (media_muestra - media_hipotetica) / error_estandar
p_valor &lt;- 2 * (1 - pnorm(abs(z_stat)))  # prueba a dos colas

cat(&quot;Media de la muestra:&quot;, round(media_muestra, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Media de la muestra: 10.7</code></pre>
<pre class="r"><code>cat(&quot;Estadistico z:&quot;, round(z_stat, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Estadistico z: 2.21</code></pre>
<pre class="r"><code>cat(&quot;p-valor:&quot;, round(p_valor, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor: 0.0268</code></pre>
</div>
<div
id="section-simulación-y-cálculo-del-pvalor-para-varianza-desconocida"
class="section level3">
<h3>5.1.2 Simulación y Cálculo del p‑valor para varianza
desconocida</h3>
<pre class="r"><code>set.seed(100)
sd_poblacional &lt;- 2 # desconocido
# Simulamos datos donde la media real es 10.5, sd=2, n=40
muestra &lt;- rnorm(40, mean = 10.5, sd = sd_poblacional)

media_muestra &lt;- mean(muestra)
n &lt;- length(muestra)
media_hipotetica &lt;- 10

sd_muestral &lt;- sd(muestra)
grados_libertad &lt;- n-1
  
# Estadístico t para H0: mu = 10 vs H1: mu != 10
error_estandar &lt;- sd_muestral / sqrt(n)
t_stat &lt;- (media_muestra - media_hipotetica) / error_estandar
p_valor &lt;- 2 * (1 - pt(abs(t_stat), df=grados_libertad))  # prueba a dos colas

cat(&quot;Media de la muestra:&quot;, round(media_muestra, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Media de la muestra: 10.7</code></pre>
<pre class="r"><code>cat(&quot;Estadistico t:&quot;, round(t_stat, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Estadistico t: 3.1</code></pre>
<pre class="r"><code>cat(&quot;p-valor:&quot;, round(p_valor, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor: 0.0035</code></pre>
<p><strong>Interpretación:</strong><br />
- Si <span class="math inline">\(\text{p-valor} &lt; \alpha\)</span>
(por ejemplo, 0.05), se rechaza H₀.<br />
- Si <span class="math inline">\(\text{p-valor} \geq \alpha\)</span>, no
se puede rechazar H₀.</p>
</div>
<div id="section-visualización-del-pvalor-en-la-distribución-normal"
class="section level3">
<h3>5.2. Visualización del p‑valor en la Distribución Normal</h3>
<pre class="r"><code># Distribución Normal Estándar
x &lt;- seq(-4, 4, length.out = 1000)
densidad &lt;- dnorm(x)
df &lt;- data.frame(x = x, densidad = densidad)

valor_obs &lt;- 1.5  # Ejemplo de estadístico observado
p_valor_ej &lt;- 2 * (1 - pnorm(abs(valor_obs)))

ggplot(df, aes(x = x, y = densidad)) +
  geom_line(size = 1) +
  # Area en las dos colas más extremas que valor_obs
  geom_area(data = subset(df, x &gt;= valor_obs),
            aes(x = x, y = densidad), alpha = 0.4) +
  geom_area(data = subset(df, x &lt;= -valor_obs),
            aes(x = x, y = densidad), alpha = 0.4) +
  labs(
    title = &quot;Distribucion Normal y Region del p-valor&quot;,
    subtitle = paste(&quot;Valor observado =&quot;, valor_obs,
                     &quot;| p-valor =&quot;, round(p_valor_ej, 4)),
    x = &quot;Valores&quot;,
    y = &quot;Densidad&quot;
  ) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<blockquote>
<p>En la gráfica, las áreas sombreadas en las colas representan la
probabilidad (p‑valor) de obtener un valor igual o más extremo que 1.5
(o -1.5) bajo H₀.</p>
</blockquote>
</div>
<div id="section-ejemplos" class="section level2">
<h2>3. Ejemplos</h2>
<div
id="section-ejemplo-1-test-de-hipótesis-para-la-media-de-una-distribución-normal"
class="section level3">
<h3>3.1. Ejemplo 1: Test de Hipótesis para la Media de una Distribución
Normal</h3>
<p>Imaginemos que queremos comprobar si la media de una variable es
10.<br />
Generamos una muestra de datos con una media real de 10.5 y evaluamos la
hipótesis:</p>
<ul>
<li><strong>H₀:</strong> µ = 10<br />
</li>
<li><strong>H₁:</strong> µ ≠ 10 Varianza desconocida Calcularemos el
p‑valor de forma manual usando la función <code>pt</code>.</li>
</ul>
<pre class="r"><code>set.seed(123)
# Simular una muestra de 10 datos de una distribución normal con media 10.5 y desviación 2
muestra &lt;- rnorm(10, mean = 10.5, sd = 2)
cat(&quot; muestra:&quot;, muestra, &quot;\n&quot;)</code></pre>
<pre><code>##  muestra: 9.379049 10.03965 13.61742 10.64102 10.75858 13.93013 11.42183 7.969878 9.126294 9.608676</code></pre>
<pre class="r"><code>media_muestra &lt;- mean(muestra)
cat(&quot;Media muestra:&quot;, media_muestra, &quot;\n&quot;)</code></pre>
<pre><code>## Media muestra: 10.64925</code></pre>
<pre class="r"><code>sd_muestra &lt;- sqrt(sum((muestra-media_muestra)**2)/(n-1))
cat(&quot;sd muestra:&quot;, sd_muestra, &quot;\n&quot;)</code></pre>
<pre><code>## sd muestra: 0.9163661</code></pre>
<pre class="r"><code># o tambien sino sd_muestra &lt;- sd(muestra)
n &lt;- length(muestra)

# Valor hipotético
media_hipotetica &lt;- 10

# Calcular el error estándar
error_est &lt;- sd_muestra / sqrt(n)

# Calcular el estadístico t (usando la aproximación normal)
t &lt;- (media_muestra - media_hipotetica) / error_est

# p-valor para una prueba de dos colas
p_valor_manual &lt;- 2 * (1 - pt(abs(t), df=n-1))
cat(&quot;Estadistico t:&quot;, t, &quot;\n&quot;)</code></pre>
<pre><code>## Estadistico t: 2.240494</code></pre>
<pre class="r"><code>cat(&quot;p-valor:&quot;, p_valor_manual, &quot;\n&quot;)</code></pre>
<pre><code>## p-valor: 0.05180143</code></pre>
<pre class="r"><code>t_test_resultado &lt;- t.test(muestra, mu = 10, type=&quot;one.sample&quot;, alternative = &quot;two.sided&quot;)
t_test_resultado</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  muestra
## t = 1.0763, df = 9, p-value = 0.3098
## alternative hypothesis: true mean is not equal to 10
## 95 percent confidence interval:
##   9.284659 12.013843
## sample estimates:
## mean of x 
##  10.64925</code></pre>
<pre class="r"><code>set.seed(1804)

n1 &lt;- 9
n2 &lt;- 11
mu_a_real &lt;- 15
mu_b_real &lt;- 17
sd_a_real &lt;- 2
sd_b_real &lt;- 3

grupo_A &lt;- rnorm(n1, mu_a_real, sd_a_real)
grupo_B &lt;- rnorm(n2, mu_b_real, sd_b_real)

cat(&quot;=== Grupo A ===\n&quot;)</code></pre>
<pre><code>## === Grupo A ===</code></pre>
<pre class="r"><code>print(grupo_A)</code></pre>
<pre><code>## [1] 12.45878 15.88824 14.69009 15.19677 14.69033 15.64319 13.83405 17.09258
## [9] 17.11884</code></pre>
<pre class="r"><code>cat(&quot;\n=== Grupo B ===\n&quot;)</code></pre>
<pre><code>## 
## === Grupo B ===</code></pre>
<pre class="r"><code>print(grupo_B)</code></pre>
<pre><code>##  [1] 18.33565 17.39671 18.05813 21.58268 16.12685 19.73508 15.52924 16.20570
##  [9] 17.22678 15.37819 21.02110</code></pre>
<pre class="r"><code>cat(&quot;\n&quot;)</code></pre>
<pre class="r"><code># ----------------------
# Paso 1: Diferencia observada entre las medias
# ----------------------
media_A &lt;- mean(grupo_A)
media_B &lt;- mean(grupo_B)
diff_obs &lt;- media_B - media_A
cat(&quot;Diferencia observada (B - A):&quot;, round(diff_obs, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Diferencia observada (B - A): 2.69</code></pre>
<pre class="r"><code># ======================
# Método 1: Prueba t asumiendo varianzas iguales (Pooled Variance)
# ======================
cat(&quot;=== Prueba t con varianzas iguales (Pooled Variance) ===\n&quot;)</code></pre>
<pre><code>## === Prueba t con varianzas iguales (Pooled Variance) ===</code></pre>
<pre class="r"><code># a) Calcular varianzas muestrales de cada grupo
var_A &lt;- var(grupo_A)
var_B &lt;- var(grupo_B)
cat(&quot;Varianza de Grupo A:&quot;, round(var_A, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Varianza de Grupo A: 2.23</code></pre>
<pre class="r"><code>cat(&quot;Varianza de Grupo B:&quot;, round(var_B, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Varianza de Grupo B: 4.56</code></pre>
<pre class="r"><code># b) Calcular la varianza combinada (pooled)
var_pooled &lt;- (((n1 - 1) * var_A) + ((n2 - 1) * var_B)) / (n1 + n2 - 2)
cat(&quot;Varianza combinada (pooled):&quot;, round(var_pooled, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Varianza combinada (pooled): 3.52</code></pre>
<pre class="r"><code># c) Calcular el error estándar de la diferencia
# Fórmula: SE = sqrt(s_p^2*(1/n1 + 1/n2))
SE_pooled &lt;- sqrt(var_pooled * (1/n1 + 1/n2))
cat(&quot;Error estándar (pooled):&quot;, round(SE_pooled, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Error estándar (pooled): 0.84</code></pre>
<pre class="r"><code># d) Calcular el estadístico t
# Fórmula: t = (mean_B - mean_A) / SE
t_stat_pooled &lt;- diff_obs / SE_pooled
cat(&quot;Estadístico t (pooled):&quot;, round(t_stat_pooled, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Estadístico t (pooled): 3.19</code></pre>
<pre class="r"><code># e) Grados de libertad
df_pooled &lt;- n1 + n2 - 2
cat(&quot;Grados de libertad (pooled):&quot;, df_pooled, &quot;\n\n&quot;)</code></pre>
<pre><code>## Grados de libertad (pooled): 18</code></pre>
<pre class="r"><code># f) Calcular los p-valores para cada alternativa:
#   - Bilateral: p = 2*(1 - pt(|t|, df))
p_valor_pooled_two &lt;- 2 * (1 - pt(abs(t_stat_pooled), df = df_pooled))
#   - Unilateral (H1: mu_B &gt; mu_A): p = 1 - pt(t, df)
p_valor_pooled_right &lt;- 1 - pt(t_stat_pooled, df = df_pooled)
#   - Unilateral (H1: mu_B &lt; mu_A): p = pt(t, df)
p_valor_pooled_left &lt;- pt(t_stat_pooled, df = df_pooled)

cat(&quot;p-valor bilateral (pooled):&quot;, round(p_valor_pooled_two, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor bilateral (pooled): 0.005</code></pre>
<pre class="r"><code>cat(&quot;p-valor unilateral (B &gt; A) (pooled):&quot;, round(p_valor_pooled_right, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor unilateral (B &gt; A) (pooled): 0.0025</code></pre>
<pre class="r"><code>cat(&quot;p-valor unilateral (B &lt; A) (pooled):&quot;, round(p_valor_pooled_left, 4), &quot;\n\n&quot;)</code></pre>
<pre><code>## p-valor unilateral (B &lt; A) (pooled): 0.9975</code></pre>
<pre class="r"><code># ======================
# Método 2: Prueba t sin asumir igualdad de varianzas (Welch&#39;s t-test)
# ======================
cat(&quot;=== Prueba t con varianzas diferentes (Welch&#39;s t-test) ===\n&quot;)</code></pre>
<pre><code>## === Prueba t con varianzas diferentes (Welch&#39;s t-test) ===</code></pre>
<pre class="r"><code># a) Calcular el error estándar sin asumir igualdad:
# Fórmula: SE = sqrt( var_A/n1 + var_B/n2 )
SE_welch &lt;- sqrt(var_A/n1 + var_B/n2)
cat(&quot;Error estándar (Welch):&quot;, round(SE_welch, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Error estándar (Welch): 0.81</code></pre>
<pre class="r"><code># b) Calcular el estadístico t para Welch
t_stat_welch &lt;- diff_obs / SE_welch
cat(&quot;Estadístico t (Welch):&quot;, round(t_stat_welch, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Estadístico t (Welch): 3.31</code></pre>
<pre class="r"><code># c) Calcular los grados de libertad con la aproximación de Welch-Satterthwaite:
# Fórmula: df = ( (var_A/n1 + var_B/n2)^2 ) / [ ((var_A/n1)^2/(n1-1)) + ((var_B/n2)^2/(n2-1)) ]
df_welch &lt;- ( (var_A/n1 + var_B/n2)^2 ) / ( ((var_A/n1)^2)/(n1 - 1) + ((var_B/n2)^2)/(n2 - 1) )
cat(&quot;Grados de libertad (Welch):&quot;, round(df_welch, 2), &quot;\n\n&quot;)</code></pre>
<pre><code>## Grados de libertad (Welch): 17.65</code></pre>
<pre class="r"><code># d) Calcular los p-valores para cada alternativa:
p_valor_welch_two &lt;- 2 * (1 - pt(abs(t_stat_welch), df = df_welch))
p_valor_welch_right &lt;- 1 - pt(t_stat_welch, df = df_welch)
p_valor_welch_left &lt;- pt(t_stat_welch, df = df_welch)

cat(&quot;p-valor bilateral (Welch):&quot;, round(p_valor_welch_two, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor bilateral (Welch): 0.004</code></pre>
<pre class="r"><code>cat(&quot;p-valor unilateral (B &gt; A) (Welch):&quot;, round(p_valor_welch_right, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor unilateral (B &gt; A) (Welch): 0.002</code></pre>
<pre class="r"><code>cat(&quot;p-valor unilateral (B &lt; A) (Welch):&quot;, round(p_valor_welch_left, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor unilateral (B &lt; A) (Welch): 0.998</code></pre>
<pre class="r"><code># Varianzas iguales - Alternativa bilateral
t.test(grupo_B, grupo_A, var.equal = TRUE, type=&quot;two.sample&quot;, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  grupo_B and grupo_A
## t = 3.1925, df = 18, p-value = 0.005045
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.9208353 4.4654992
## sample estimates:
## mean of x mean of y 
##  17.87238  15.17921</code></pre>
<pre class="r"><code># Varianzas iguales - Alternativa B &gt; A
t.test(grupo_B, grupo_A, var.equal = TRUE, type=&quot;two.sample&quot;,alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  grupo_B and grupo_A
## t = 3.1925, df = 18, p-value = 0.002523
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  1.230316      Inf
## sample estimates:
## mean of x mean of y 
##  17.87238  15.17921</code></pre>
<pre class="r"><code># Varianzas iguales - Alternativa B &lt; A
t.test(grupo_B, grupo_A, var.equal = TRUE, type=&quot;two.sample&quot;,alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  grupo_B and grupo_A
## t = 3.1925, df = 18, p-value = 0.9975
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##      -Inf 4.156018
## sample estimates:
## mean of x mean of y 
##  17.87238  15.17921</code></pre>
<pre class="r"><code># Varianzas diferentes (Welch) - Alternativa bilateral
t.test(grupo_B, grupo_A, var.equal = FALSE, type=&quot;two.sample&quot;,alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  grupo_B and grupo_A
## t = 3.3101, df = 17.646, p-value = 0.003976
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.9813397 4.4049948
## sample estimates:
## mean of x mean of y 
##  17.87238  15.17921</code></pre>
<pre class="r"><code># Varianzas diferentes (Welch) - Alternativa B &gt; A
t.test(grupo_B, grupo_A, var.equal = FALSE, type=&quot;two.sample&quot;,alternative = &quot;greater&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  grupo_B and grupo_A
## t = 3.3101, df = 17.646, p-value = 0.001988
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  1.280752      Inf
## sample estimates:
## mean of x mean of y 
##  17.87238  15.17921</code></pre>
<pre class="r"><code># Varianzas diferentes (Welch) - Alternativa B &lt; A
t.test(grupo_B, grupo_A, var.equal = FALSE, type=&quot;two.sample&quot;,alternative = &quot;less&quot;)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  grupo_B and grupo_A
## t = 3.3101, df = 17.646, p-value = 0.998
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##      -Inf 4.105583
## sample estimates:
## mean of x mean of y 
##  17.87238  15.17921</code></pre>
</div>
<div
id="section-ejemplo-2-test-de-hipótesis-en-un-experimento-de-lanzamiento-de-moneda"
class="section level3">
<h3>3.2. Ejemplo 2: Test de Hipótesis en un Experimento de Lanzamiento
de Moneda</h3>
<p>Supongamos que lanzamos una moneda pesada varias veces y queremos
comprobar si es tan pesada como nos reporta su fabricante (probabilidad
de cara teorica = 0.7).</p>
<ul>
<li><strong>H₀:</strong> La moneda esta bien cargada (p = 0.7)<br />
</li>
<li><strong>H₁:</strong> La moneda no esta bien cargada (p ≠ 0.7)</li>
</ul>
<p>La prueba que realizamos es una <strong>prueba binomial de dos
colas</strong>, porque no solo nos interesa si hay demasiadas caras,
sino también si hay demasiado pocas.</p>
<hr />
<p>El p‑valor se calcula como el área más extrema (o más rara) que la
observación, <strong>en ambos extremos</strong> de la distribución:</p>
<pre class="r"><code>p_valor_binom &lt;- 2 * min(
  pbinom(65, size = 100, prob = 0.7),
  1 - pbinom(65 - 1, size = 100, prob = 0.7)
)
p_valor_binom</code></pre>
<pre><code>## [1] 0.3257166</code></pre>
<p>Esto se hace porque: - <code>pbinom(caras)</code> da la probabilidad
acumulada hasta ese número (casos “menores”). -
<code>1 - pbinom(caras - 1)</code> da la probabilidad acumulada desde
ese número hacia arriba (casos “mayores”).</p>
<p>Tomamos el <strong>mínimo</strong> de los dos porque en una prueba
bilateral nos interesa duplicar <strong>la cola más extrema</strong>, no
ambas sumadas (eso sobredimensionaría el p‑valor).</p>
<p>Intervalos de confianza</p>
<pre class="r"><code>exitos &lt;- 65
fracasos &lt;- 100 - exitos
alpha &lt;- 0.05
cat(qbeta(alpha/2, exitos, fracasos + 1))  # Límite inferior</code></pre>
<pre><code>## 0.5481506</code></pre>
<pre class="r"><code>cat(qbeta(1- alpha/2, exitos + 1, fracasos))  # Límite superior</code></pre>
<pre><code>## 0.7427062</code></pre>
<p>Aproximacion Normal</p>
<pre class="r"><code>p_hat &lt;- exitos/100
rango &lt;- qnorm(alpha/2)*sqrt(p_hat * (1-p_hat) / 100)
cat(p_hat + rango)</code></pre>
<pre><code>## 0.5565157</code></pre>
<pre class="r"><code>cat(p_hat - rango)</code></pre>
<pre><code>## 0.7434843</code></pre>
<pre class="r"><code>library(shiny)
library(ggplot2)

ui &lt;- fluidPage(
  titlePanel(&quot;Test de Hipótesis con Lanzamientos de Moneda&quot;),
  sidebarLayout(
    sidebarPanel(
      sliderInput(&quot;n&quot;, &quot;Número de lanzamientos:&quot;, min = 10, max = 500, value = 100, step = 10),
      sliderInput(&quot;p_real&quot;, &quot;Probabilidad real de cara:&quot;, min = 0.01, max = 0.99, value = 0.5, step = 0.01)
    ),
    mainPanel(
      verbatimTextOutput(&quot;resultados&quot;),
      plotOutput(&quot;grafico&quot;)
    )
  )
)

server &lt;- function(input, output) {
  output$resultados &lt;- renderPrint({
    set.seed(456)
    # Usamos la probabilidad real para generar los datos
    lanzamientos &lt;- rbinom(input$n, size = 1, prob = input$p_real)
    caras &lt;- sum(lanzamientos)

    # Hacemos el test como si la moneda fuera calibrada
    p_valor &lt;- 2 * min(
      pbinom(caras, size = input$n, prob = 0.7),
      1 - pbinom(caras - 1, size = input$n, prob = 0.7)
    )

    cat(&quot;Número de lanzamientos:&quot;, input$n, &quot;\n&quot;)
    cat(&quot;Probabilidad real de cara:&quot;, input$p_real, &quot;\n&quot;)
    cat(&quot;Número de caras observadas:&quot;, caras, &quot;\n&quot;)
    cat(&quot;p-valor (hipótesis: p = 0.5):&quot;, round(p_valor, 4), &quot;\n&quot;)
  })

  output$grafico &lt;- renderPlot({
    set.seed(456)
    lanzamientos &lt;- rbinom(input$n, size = 1, prob = input$p_real)
    caras &lt;- sum(lanzamientos)

    x_vals &lt;- 0:input$n
    densidad &lt;- dbinom(x_vals, size = input$n, prob = 0.7)
    df &lt;- data.frame(x = x_vals, densidad = densidad)

    ggplot(df, aes(x = x, y = densidad)) +
      geom_bar(stat = &quot;identity&quot;, fill = &quot;lightblue&quot;, color = &quot;black&quot;) +
      geom_vline(xintercept = caras, color = &quot;red&quot;, size = 1) +
      labs(title = paste(&quot;Distribución Binomial bajo H₀ (n =&quot;, input$n, &quot;, p = 0.7)&quot;),
           subtitle = paste(&quot;Datos generados con p_real =&quot;, input$p_real,
                            &quot;→ caras observadas =&quot;, caras),
           x = &quot;Número de caras&quot;,
           y = &quot;Probabilidad&quot;) +
      theme_minimal()
  })
}

shinyApp(ui, server)</code></pre>
<iframe data-deferred-src="appdbc055d504b7eab961e2ab93dd55b97d/?w=&amp;__subapp__=1" width="100%" height="400" class="shiny-frame shiny-frame-deferred"></iframe>
</div>
</div>
<div id="section-ejercicios" class="section level2">
<h2>4. Ejercicios</h2>
</div>
<div id="section-ejercicio-1-media-de-una-distribución-normal"
class="section level2">
<h2>### Ejercicio 1: Media de una Distribución Normal</h2>
<p>Simulen una muestra de 40 datos de una distribución normal con media
15 y desviación 3. Planteen la hipótesis:<br />
- H₀: La media es 14.<br />
- H₁: La media es diferente de 14.<br />
Calcular el estadístico (z) y el p‑valor manualmente.<br />
- <strong>Pista:</strong> Use funciones <code>rnorm()</code>,
<code>mean()</code>, <code>sd()</code>, y <code>pnorm()</code>.</p>
</div>
<div id="section-ejercicio-2-visualización-del-pvalor"
class="section level2">
<h2>### Ejercicio 2: Visualización del p‑valor</h2>
<p>Utilizando ggplot2, grafiquen la distribución normal estándar y
marquen la región que corresponde al p‑valor para un valor observado de
2.2 en una prueba de dos colas.<br />
- <strong>Pista:</strong> Use <code>geom_area()</code> para sombrear las
colas de la distribución.</p>
</div>
<div id="section-ejercicio-3-experimento-de-lanzamiento-de-moneda"
class="section level2">
<h2>### Ejercicio 3: Experimento de Lanzamiento de Moneda</h2>
<p>Simulen 200 lanzamientos de una moneda (con probabilidad 0.5) y
supongan que obtuvieron un número inusual de caras (por ejemplo, 130
sobre 200).<br />
Calcular el p‑valor usando la distribución binomial y explique si se
rechazaría la hipótesis de moneda justa (usando α = 0.05).<br />
- <strong>Pista:</strong> Use <code>rbinom()</code>,
<code>pbinom()</code> y visualice la distribución.</p>
<div id="section-ejercicio-4-comparación-de-medias-mediante-remuestreo"
class="section level3">
<h3>Ejercicio 4: Comparación de Medias mediante Re‑muestreo</h3>
<p>Simulen dos grupos independientes de 50 observaciones cada uno.<br />
- Grupo A: datos generados de una distribución normal con media 20 y
desviación 2.<br />
- Grupo B: datos generados de una distribución normal con media 22 y
desviación 2.</p>
<p>Planteen la hipótesis nula H₀: µₐ = µ_b contra la alternativa H₁: µₐ
≠ µ_b.<br />
Realicen lo siguiente:<br />
1. Calcular la diferencia de medias observada.<br />
2. Combinar ambos grupos y, mediante re‑muestreo (1000 simulaciones),
generar la distribución de la diferencia de medias bajo H₀ asignando
aleatoriamente los datos en dos grupos de 50 observaciones.<br />
3. Calcular el p‑valor como la proporción de simulaciones en las que la
diferencia absoluta simulada es mayor o igual a la diferencia
observada.<br />
4. Visualizar la distribución de las diferencias simuladas y marcar la
diferencia observada.</p>
</div>
</div>
<div id="section-resoluciones-de-los-ejercicios" class="section level2">
<h2>5. Resoluciones de los Ejercicios</h2>
<div id="section-resolución-ejercicio-1" class="section level3">
<h3>Resolución Ejercicio 1</h3>
<pre class="r"><code>set.seed(101)
# Simular 40 datos con media = 15 y sd = 3
muestra_e1 &lt;- rnorm(40, mean = 15, sd = 3)
media_muestra_e1 &lt;- mean(muestra_e1)
sd_muestra_e1 &lt;- sd(muestra_e1)
n_e1 &lt;- length(muestra_e1)

# Hipótesis: H₀: µ = 14, H₁: µ ≠ 14
media_hipotetica_e1 &lt;- 14
error_est_e1 &lt;- sd_muestra_e1 / sqrt(n_e1)
z_e1 &lt;- (media_muestra_e1 - media_hipotetica_e1) / error_est_e1
p_valor_e1 &lt;- 2 * (1 - pnorm(abs(z_e1)))

cat(&quot;Media de la muestra:&quot;, round(media_muestra_e1,2), &quot;\n&quot;)</code></pre>
<pre><code>## Media de la muestra: 14.85</code></pre>
<pre class="r"><code>cat(&quot;Estadístico z:&quot;, round(z_e1,2), &quot;\n&quot;)</code></pre>
<pre><code>## Estadístico z: 1.96</code></pre>
<pre class="r"><code>cat(&quot;p-valor:&quot;, round(p_valor_e1,4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor: 0.0501</code></pre>
</div>
<div id="section-resolución-ejercicio-2" class="section level3">
<h3>Resolución Ejercicio 2</h3>
<pre class="r"><code>library(ggplot2)
# Distribución normal estándar
x &lt;- seq(-4, 4, length.out = 1000)
df2 &lt;- data.frame(x = x, densidad = dnorm(x))
valor_obs_e2 &lt;- 2.2
p_valor_e2 &lt;- 2 * (1 - pnorm(valor_obs_e2))

ggplot(df2, aes(x = x, y = densidad)) +
  geom_line(color = &quot;blue&quot;, size = 1) +
  geom_area(data = subset(df2, x &gt;= valor_obs_e2), aes(y = densidad), fill = &quot;red&quot;, alpha = 0.4) +
  geom_area(data = subset(df2, x &lt;= -valor_obs_e2), aes(y = densidad), fill = &quot;red&quot;, alpha = 0.4) +
  labs(title = &quot;Distribución Normal Estándar y Región del p-valor&quot;,
       subtitle = paste(&quot;Valor observado =&quot;, valor_obs_e2, &quot;| p-valor =&quot;, round(p_valor_e2,4)),
       x = &quot;Valores&quot;, y = &quot;Densidad&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="section-resolución-ejercicio-3" class="section level3">
<h3>Resolución Ejercicio 3</h3>
<pre class="r"><code>set.seed(202)
# Simular 200 lanzamientos de moneda
lanzamientos_e3 &lt;- rbinom(200, size = 1, prob = 0.5)
caras_e3 &lt;- sum(lanzamientos_e3)

# Supongamos que se obtuvieron 130 caras en la simulación
# Para efectos del ejercicio, forzamos el valor:
caras_e3 &lt;- 130

# Calcular el p-valor para una prueba de dos colas
p_valor_binom_e3 &lt;- 2 * min(
  pbinom(caras_e3, size = 200, prob = 0.5),
  1 - pbinom(caras_e3 - 1, size = 200, prob = 0.5)
)

cat(&quot;Número de caras:&quot;, caras_e3, &quot;\n&quot;)</code></pre>
<pre><code>## Número de caras: 130</code></pre>
<pre class="r"><code>cat(&quot;p-valor (binomial):&quot;, round(p_valor_binom_e3,9), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor (binomial): 2.6529e-05</code></pre>
<pre class="r"><code># Con α = 0.05, si el p-valor es menor, se rechaza la hipótesis de moneda justa.</code></pre>
</div>
<div id="section-resolución-ejercicio-4" class="section level3">
<h3>Resolución Ejercicio 4</h3>
<pre class="r"><code>set.seed(2025)
library(ggplot2)

grupo_A &lt;- rnorm(50, mean = 20, sd = 2)
grupo_B &lt;- rnorm(50, mean = 22, sd = 2)
diff_obs &lt;- mean(grupo_B) - mean(grupo_A)
pool &lt;- c(grupo_A, grupo_B)
n &lt;- length(grupo_A)
n_sim &lt;- 1000
diff_sim &lt;- replicate(n_sim, {
  muestra &lt;- sample(pool)
  mean(muestra[(n+1):(2*n)]) - mean(muestra[1:n])
})
p_valor &lt;- mean(abs(diff_sim) &gt;= abs(diff_obs))
ggplot(data.frame(diff_sim = diff_sim), aes(x = diff_sim)) +
  geom_histogram(bins = 30, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  geom_vline(xintercept = diff_obs, color = &quot;red&quot;, size = 1.2) +
  labs(title = &quot;Distribución de Diferencias de Medias Simuladas&quot;,
       subtitle = paste(&quot;Diferencia Observada =&quot;, round(diff_obs, 2),
                        &quot;| p-valor =&quot;, round(p_valor, 4)),
       x = &quot;Diferencia de Medias&quot;, y = &quot;Frecuencia&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
</div>
<div id="section-test-de-independencia" class="section level2">
<h2>3. Test de Independencia</h2>
<div id="section-concepto-y-uso" class="section level3">
<h3>3.1. Concepto y Uso</h3>
<p>El <strong>test de independencia</strong> se utiliza para determinar
si dos variables categóricas son estadísticamente independientes. Por lo
general, se emplea el test chi-cuadrado de independencia.</p>
<ul>
<li><strong>Hipótesis:</strong>
<ul>
<li><strong>H₀:</strong> Las dos variables son independientes.</li>
<li><strong>H₁:</strong> Existe una asociación (dependencia) entre las
dos variables.</li>
</ul></li>
</ul>
</div>
<div id="section-ejemplo-super-sencillo" class="section level3">
<h3>3.2.0 Ejemplo super sencillo</h3>
<pre class="r"><code>observado &lt;- matrix(c(35, 25, 20, 20), nrow = 2, byrow = TRUE)
rownames(observado) &lt;- c(&quot;Masculino&quot;, &quot;Femenino&quot;)
colnames(observado) &lt;- c(&quot;Sí&quot;, &quot;No&quot;)
observado</code></pre>
<pre><code>##           Sí No
## Masculino 35 25
## Femenino  20 20</code></pre>
<pre class="r"><code>fila_totales &lt;- rowSums(observado)
col_totales &lt;- colSums(observado)
total &lt;- sum(observado)

esperado &lt;- outer(fila_totales, col_totales) / total
esperado</code></pre>
<pre><code>##           Sí No
## Masculino 33 27
## Femenino  22 18</code></pre>
<pre class="r"><code>chi2_manual &lt;- sum((observado - esperado)^2 / esperado)
chi2_manual</code></pre>
<pre><code>## [1] 0.6734007</code></pre>
<p>Ahora hay que comparar el estadistico para saber su probabilidad y
p-valor</p>
<pre class="r"><code>df &lt;- (nrow(observado) - 1) * (ncol(observado) - 1)
alpha &lt;- 0.05
valor_critico &lt;- qchisq(1 - alpha, df)
valor_critico</code></pre>
<pre><code>## [1] 3.841459</code></pre>
<pre class="r"><code>if (chi2_manual &gt; valor_critico) {
  cat(&quot;Se rechaza H0\n&quot;)
} else {
  cat(&quot;No se rechaza H0\n&quot;)
}</code></pre>
<pre><code>## No se rechaza H0</code></pre>
<p>P valor seria</p>
<pre class="r"><code>pchisq(chi2_manual, df=1)</code></pre>
<pre><code>## [1] 0.5881315</code></pre>
</div>
<div id="section-ejemplo-práctico-con-datos-simulados"
class="section level3">
<h3>3.2.1 Ejemplo Práctico con Datos Simulados</h3>
<p>Imaginemos un escenario donde se evalúa la relación entre el género
(Masculino, Femenino) y la preferencia por un producto (Sí, No).</p>
<pre class="r"><code># Crear una tabla de contingencia simulada
genero &lt;- c(rep(&quot;Masculino&quot;, 60), rep(&quot;Femenino&quot;, 40))
preferencia &lt;- c(sample(c(&quot;Sí&quot;, &quot;No&quot;), 60, replace = TRUE, prob = c(0.7, 0.3)),
                 sample(c(&quot;Sí&quot;, &quot;No&quot;), 40, replace = TRUE, prob = c(0.4, 0.6)))
datos_cat &lt;- data.frame(genero, preferencia)

# Crear la tabla de contingencia
tabla_contingencia &lt;- table(datos_cat$genero, datos_cat$preferencia)
print(tabla_contingencia)</code></pre>
<pre><code>##            
##             No Sí
##   Femenino  23 17
##   Masculino 19 41</code></pre>
<pre class="r"><code># Realizar el test de chi-cuadrado de independencia
test_independencia &lt;- chisq.test(tabla_contingencia)
print(test_independencia)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  tabla_contingencia
## X-squared = 5.5573, df = 1, p-value = 0.0184</code></pre>
<p><em>Interpretación:</em><br />
Si el p‑valor es menor a 0.05 se rechaza H₀, indicando que existe una
asociación entre el género y la preferencia por el producto.</p>
</div>
<div id="section-visualización-de-la-tabla-de-contingencia"
class="section level3">
<h3>3.3. Visualización de la Tabla de Contingencia</h3>
<pre class="r"><code>library(ggplot2)

# Create the plot
ggplot(datos_cat, aes(x = genero, fill = preferencia)) +
  geom_bar(position = &quot;fill&quot;) +  # &quot;fill&quot; makes it proportional
  labs(title = &quot;Distribución de Preferencia por Género&quot;,
       x = &quot;Género&quot;,
       y = &quot;Proporción&quot;,
       fill = &quot;Preferencia&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code># Simulación de datos
set.seed(123)

grupo_etario &lt;- c(rep(&quot;10-30&quot;, 100), rep(&quot;30-50&quot;, 100), rep(&quot;50-80&quot;, 100))
genero_pelicula &lt;- c(
  sample(c(&quot;Comedia&quot;, &quot;Acción&quot;, &quot;Romance&quot;), 100, replace = TRUE, prob = c(0.5, 0.4, 0.1)),
  sample(c(&quot;Comedia&quot;, &quot;Acción&quot;, &quot;Romance&quot;), 100, replace = TRUE, prob = c(0.3, 0.5, 0.2)),
  sample(c(&quot;Comedia&quot;, &quot;Acción&quot;, &quot;Romance&quot;), 100, replace = TRUE, prob = c(0.2, 0.2, 0.6))
)

datos_cat_ext &lt;- data.frame(grupo_etario, genero_pelicula)

# Crear la tabla de contingencia
tabla_contingencia_ext &lt;- table(datos_cat_ext$grupo_etario, datos_cat_ext$genero_pelicula)
print(tabla_contingencia_ext)</code></pre>
<pre><code>##        
##         Acción Comedia Romance
##   10-30     40      53       7
##   30-50     50      31      19
##   50-80     20      19      61</code></pre>
<pre class="r"><code># Realizar el test de chi-cuadrado de independencia
test_independencia_ext &lt;- chisq.test(tabla_contingencia_ext)
print(test_independencia_ext)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tabla_contingencia_ext
## X-squared = 85.496, df = 4, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>ggplot(datos_cat_ext, aes(x = grupo_etario, fill = genero_pelicula)) +
  geom_bar(position = &quot;fill&quot;) +
  labs(title = &quot;Preferencias de Género de Película por Grupo Etario&quot;,
       x = &quot;Grupo Etario&quot;,
       y = &quot;Proporción&quot;,
       fill = &quot;Género de Película&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
</div>
<div id="section-ejercicios-1" class="section level2">
<h2>4. Ejercicios</h2>
<div id="section-ejercicio-2-potencia-de-la-prueba"
class="section level3">
<h3>Ejercicio 2: Potencia de la Prueba</h3>
<p>Simule una muestra de 50 datos con una media de 12 y desviación 3.
Plantee la prueba: - H₀: µ = 10 - H₁: µ ≠ 10</p>
<p>Utilice la función <code>power.t.test()</code> para determinar el
tamaño muestral necesario para alcanzar una potencia de al menos 0.85,
considerando un tamaño del efecto (diferencia) de 2, una desviación
estándar de 3 y un nivel de significancia de 0.05.</p>
</div>
</div>
<div id="section-ejercicio-3-test-de-independencia"
class="section level2">
<h2>### Ejercicio 3: Test de Independencia</h2>
<p>Dado el siguiente conjunto de datos simulados que representan la
relación entre el tipo de estudio (Presencial, Virtual) y la
satisfacción (Alta, Media, Baja) de los estudiantes.</p>
<p>set.seed(123) tipo_estudio &lt;- sample(c(“Presencial”, “Virtual”),
size = 150, replace = TRUE, prob = c(0.6, 0.4)) satisfaccion &lt;-
sample(c(“Alta”, “Media”, “Baja”), size = 150, replace = TRUE, prob =
c(0.5, 0.3, 0.2)) datos_e3 &lt;- data.frame(tipo_estudio,
satisfaccion)</p>
<p>Realice lo siguiente:<br />
1. Construya la tabla de contingencia.<br />
2. Realice el test de chi-cuadrado para determinar si existe una
relación entre las dos variables.<br />
3. Visualice los resultados utilizando un gráfico de mosaico.</p>
</div>
<div id="section-resoluciones-de-los-ejercicios-1"
class="section level2">
<h2>5. Resoluciones de los Ejercicios</h2>
<div id="section-resolución-ejercicio-2-potencia-de-la-prueba"
class="section level3">
<h3>Resolución Ejercicio 2: Potencia de la Prueba</h3>
<pre class="r"><code># Determinar el tamaño muestral necesario para una potencia de 0.85
resultado_potencia &lt;- power.t.test(delta = 2, sd = 3, sig.level = 0.05, power = 0.85, type = &quot;one.sample&quot;, alternative = &quot;two.sided&quot;)
print(resultado_potencia)</code></pre>
<pre><code>## 
##      One-sample t test power calculation 
## 
##               n = 22.20435
##           delta = 2
##              sd = 3
##       sig.level = 0.05
##           power = 0.85
##     alternative = two.sided</code></pre>
<p><em>Comentario:</em><br />
El resultado indicará el tamaño muestral necesario por grupo para
alcanzar una potencia de al menos 85% dado el tamaño del efecto y la
variabilidad propuesta.</p>
</div>
<div id="section-resolución-ejercicio-3-test-de-independencia"
class="section level3">
<h3>Resolución Ejercicio 3: Test de Independencia</h3>
<pre class="r"><code># Simulación de datos: Tipo de estudio y Satisfacción
set.seed(123)
tipo_estudio &lt;- sample(c(&quot;Presencial&quot;, &quot;Virtual&quot;), size = 150, replace = TRUE, prob = c(0.6, 0.4))
satisfaccion &lt;- sample(c(&quot;Alta&quot;, &quot;Media&quot;, &quot;Baja&quot;), size = 150, replace = TRUE, prob = c(0.5, 0.3, 0.2))
datos_e3 &lt;- data.frame(tipo_estudio, satisfaccion)

# Tabla de contingencia
tabla_e3 &lt;- table(datos_e3$tipo_estudio, datos_e3$satisfaccion)
print(tabla_e3)</code></pre>
<pre><code>##             
##              Alta Baja Media
##   Presencial   45   19    25
##   Virtual      32    8    21</code></pre>
<pre class="r"><code># Test de chi-cuadrado de independencia
test_e3 &lt;- chisq.test(tabla_e3)
print(test_e3)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tabla_e3
## X-squared = 1.8623, df = 2, p-value = 0.3941</code></pre>
<pre class="r"><code>library(ggplot2)

# Create the stacked bar chart
ggplot(datos_e3, aes(x = tipo_estudio, fill = satisfaccion)) +
  geom_bar(position = &quot;fill&quot;) +  # &quot;fill&quot; makes it proportional
  labs(title = &quot;Distribución de Satisfacción por Tipo de Estudio&quot;,
       x = &quot;Tipo de Estudio&quot;,
       y = &quot;Proporción&quot;,
       fill = &quot;Satisfacción&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
</div>
</div>
<div
id="section-test-de-permutaciones-para-variables-cualitativas-proporciones"
class="section level2">
<h2>2. Test de Permutaciones para Variables Cualitativas
(Proporciones)</h2>
<div id="section-concepto-y-uso-1" class="section level3">
<h3>Concepto y Uso</h3>
<p>El <strong>test de permutaciones</strong> es un método no paramétrico
que consiste en reordenar aleatoriamente las etiquetas de grupo para
evaluar la significancia de la diferencia observada en la proporción
entre dos grupos.<br />
- <strong>Proceso:</strong><br />
1. Calcular la diferencia observada en la proporción entre dos
grupos.<br />
2. Permutar (reordenar) las etiquetas muchas veces y calcular la
diferencia en cada permutación.<br />
3. Estimar el p‑valor como la proporción de permutaciones en las que la
diferencia es al menos tan extrema como la observada.</p>
</div>
<div id="section-ejemplo-práctico" class="section level3">
<h3>Ejemplo Práctico</h3>
<p>Simulamos dos grupos de 80 observaciones cada uno, donde en el Grupo
A la proporción de “Sí” es 0.70 y en el Grupo B es 0.55. Se evalúa si la
diferencia es significativa mediante 5000 permutaciones.</p>
<pre class="r"><code>set.seed(456)
n &lt;- 80
grupo &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), each = n)
respuesta &lt;- c(
  sample(c(&quot;Sí&quot;, &quot;No&quot;), size = n, replace = TRUE, prob = c(0.70, 0.30)),
  sample(c(&quot;Sí&quot;, &quot;No&quot;), size = n, replace = TRUE, prob = c(0.55, 0.45))
)
datos_perm &lt;- data.frame(grupo, respuesta)
datos_perm</code></pre>
<pre><code>##     grupo respuesta
## 1       A        Sí
## 2       A        Sí
## 3       A        No
## 4       A        No
## 5       A        No
## 6       A        Sí
## 7       A        Sí
## 8       A        Sí
## 9       A        Sí
## 10      A        Sí
## 11      A        Sí
## 12      A        Sí
## 13      A        No
## 14      A        No
## 15      A        Sí
## 16      A        Sí
## 17      A        No
## 18      A        Sí
## 19      A        No
## 20      A        Sí
## 21      A        Sí
## 22      A        No
## 23      A        No
## 24      A        Sí
## 25      A        No
## 26      A        No
## 27      A        No
## 28      A        Sí
## 29      A        Sí
## 30      A        Sí
## 31      A        No
## 32      A        Sí
## 33      A        No
## 34      A        Sí
## 35      A        Sí
## 36      A        No
## 37      A        No
## 38      A        No
## 39      A        No
## 40      A        Sí
## 41      A        Sí
## 42      A        Sí
## 43      A        Sí
## 44      A        Sí
## 45      A        Sí
## 46      A        Sí
## 47      A        Sí
## 48      A        Sí
## 49      A        Sí
## 50      A        No
## 51      A        No
## 52      A        No
## 53      A        Sí
## 54      A        Sí
## 55      A        Sí
## 56      A        No
## 57      A        No
## 58      A        Sí
## 59      A        Sí
## 60      A        Sí
## 61      A        Sí
## 62      A        Sí
## 63      A        Sí
## 64      A        Sí
## 65      A        Sí
## 66      A        Sí
## 67      A        Sí
## 68      A        Sí
## 69      A        Sí
## 70      A        Sí
## 71      A        No
## 72      A        No
## 73      A        Sí
## 74      A        Sí
## 75      A        Sí
## 76      A        Sí
## 77      A        Sí
## 78      A        Sí
## 79      A        Sí
## 80      A        Sí
## 81      B        Sí
## 82      B        Sí
## 83      B        No
## 84      B        No
## 85      B        Sí
## 86      B        No
## 87      B        Sí
## 88      B        Sí
## 89      B        No
## 90      B        No
## 91      B        Sí
## 92      B        No
## 93      B        Sí
## 94      B        No
## 95      B        No
## 96      B        No
## 97      B        Sí
## 98      B        Sí
## 99      B        No
## 100     B        No
## 101     B        Sí
## 102     B        Sí
## 103     B        Sí
## 104     B        Sí
## 105     B        No
## 106     B        No
## 107     B        No
## 108     B        No
## 109     B        No
## 110     B        Sí
## 111     B        No
## 112     B        Sí
## 113     B        Sí
## 114     B        No
## 115     B        No
## 116     B        No
## 117     B        No
## 118     B        No
## 119     B        No
## 120     B        No
## 121     B        Sí
## 122     B        Sí
## 123     B        Sí
## 124     B        No
## 125     B        Sí
## 126     B        No
## 127     B        No
## 128     B        Sí
## 129     B        Sí
## 130     B        Sí
## 131     B        No
## 132     B        Sí
## 133     B        No
## 134     B        No
## 135     B        Sí
## 136     B        No
## 137     B        Sí
## 138     B        No
## 139     B        Sí
## 140     B        No
## 141     B        Sí
## 142     B        Sí
## 143     B        Sí
## 144     B        Sí
## 145     B        Sí
## 146     B        No
## 147     B        No
## 148     B        No
## 149     B        Sí
## 150     B        No
## 151     B        No
## 152     B        No
## 153     B        Sí
## 154     B        Sí
## 155     B        Sí
## 156     B        No
## 157     B        Sí
## 158     B        No
## 159     B        No
## 160     B        No</code></pre>
<p>Diferencia observada en la proporción de “Sí”</p>
<pre class="r"><code>prop_A &lt;- mean(datos_perm$respuesta[datos_perm$grupo == &quot;A&quot;] == &quot;Sí&quot;)
prop_B &lt;- mean(datos_perm$respuesta[datos_perm$grupo == &quot;B&quot;] == &quot;Sí&quot;)
diff_obs &lt;- prop_A - prop_B
diff_obs</code></pre>
<pre><code>## [1] 0.225</code></pre>
<pre class="r"><code># Permutaciones: 5000 réplicas
n_perm &lt;- 5000
dif_perm &lt;- replicate(n_perm, {
  grupo_perm &lt;- sample(datos_perm$grupo)
  prop_A_perm &lt;- mean(datos_perm$respuesta[grupo_perm == &quot;A&quot;] == &quot;Sí&quot;)
  prop_B_perm &lt;- mean(datos_perm$respuesta[grupo_perm == &quot;B&quot;] == &quot;Sí&quot;)
  prop_A_perm - prop_B_perm
})

# p-valor (test bilateral)
p_valor_perm &lt;- mean(abs(dif_perm) &gt;= abs(diff_obs))
cat(&quot;p-valor de permutación:&quot;, round(p_valor_perm, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor de permutación: 0.0058</code></pre>
<pre class="r"><code># Visualización de la distribución de diferencias
df_perm &lt;- data.frame(diff = dif_perm)
ggplot(df_perm, aes(x = diff)) +
  geom_histogram(bins = 30, fill = &quot;lightgreen&quot;, color = &quot;black&quot;, alpha = 0.7) +
  geom_vline(xintercept = diff_obs, color = &quot;red&quot;, linetype = &quot;dashed&quot;, size = 1.2) +
  labs(title = &quot;Distribución de Diferencias en Proporciones (Permutaciones)&quot;,
       x = &quot;Diferencia (Grupo A - Grupo B)&quot;, y = &quot;Frecuencia&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
</div>
</div>
<div id="section-test-exacto-de-fisher" class="section level2">
<h2>4. Test Exacto de Fisher</h2>
<div id="section-concepto-y-uso-2" class="section level3">
<h3>Concepto y Uso</h3>
<p>El <strong>test exacto de Fisher</strong> es utilizado para evaluar
la asociación en tablas de contingencia 2×2 cuando las frecuencias son
bajas.<br />
- <strong>Hipótesis:</strong><br />
- H₀: No existe asociación entre las dos variables.<br />
- H₁: Existe asociación. - <strong>Ventaja:</strong> Es exacto y no
depende de aproximaciones asintóticas.</p>
</div>
<div id="section-ejemplo-práctico-1" class="section level3">
<h3>Ejemplo Práctico</h3>
<p>Se simula una tabla 2×2 con datos pequeños, por ejemplo, para evaluar
la asociación entre “Tratamiento” (Sí/No) y “Respuesta”
(Éxito/Fracaso).</p>
<pre class="r"><code># Crear tabla 2×2
tabla_fisher &lt;- matrix(c(8, 2, 1, 9), nrow = 2,
                       dimnames = list(Tratamiento = c(&quot;Sí&quot;, &quot;No&quot;),
                                       Respuesta = c(&quot;Éxito&quot;, &quot;Fracaso&quot;)))
print(tabla_fisher)</code></pre>
<pre><code>##            Respuesta
## Tratamiento Éxito Fracaso
##          Sí     8       1
##          No     2       9</code></pre>
<pre class="r"><code># Test exacto de Fisher
test_fisher &lt;- fisher.test(tabla_fisher)
print(test_fisher)</code></pre>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tabla_fisher
## p-value = 0.005477
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##     2.057999 1740.081669
## sample estimates:
## odds ratio 
##   27.32632</code></pre>
</div>
</div>
<div id="section-test-de-normalidad" class="section level2">
<h2>5. Test de Normalidad</h2>
<div id="section-concepto-y-uso-3" class="section level3">
<h3>Concepto y Uso</h3>
<ul>
<li><strong>Test común:</strong> Shapiro-Wilk.<br />
</li>
<li><strong>Complemento visual:</strong> Q-Q plot y histogramas.</li>
</ul>
</div>
<div id="section-ejemplo-práctico-2" class="section level3">
<h3>Ejemplo Práctico</h3>
<p>Aplicamos el test de Shapiro-Wilk a la variable <em>Sepal.Length</em>
del dataset <em>iris</em> y generamos un Q-Q plot para visualizar la
normalidad.</p>
<pre class="r"><code># Test de Shapiro-Wilk para Sepal.Length
shapiro_result &lt;- shapiro.test(iris$Sepal.Length)
print(shapiro_result)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  iris$Sepal.Length
## W = 0.97609, p-value = 0.01018</code></pre>
<pre class="r"><code>shapiro_result &lt;- shapiro.test(rnorm(150))
print(shapiro_result)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rnorm(150)
## W = 0.99352, p-value = 0.7387</code></pre>
<pre class="r"><code>shapiro_result &lt;- shapiro.test(rexp(150, rate=1))
print(shapiro_result)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rexp(150, rate = 1)
## W = 0.82272, p-value = 3.406e-12</code></pre>
<pre class="r"><code>shapiro_result &lt;- shapiro.test(runif(150, min=0, max=1))
print(shapiro_result)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  runif(150, min = 0, max = 1)
## W = 0.96563, p-value = 0.0008387</code></pre>
<pre class="r"><code># Q-Q plot con ggplot2
ggplot(iris, aes(sample = Sepal.Length)) +
  stat_qq(color = &quot;blue&quot;) +
  stat_qq_line(color = &quot;red&quot;) +
  labs(title = &quot;Q-Q Plot de Sepal.Length&quot;,
       x = &quot;Cuantiles teóricos&quot;, y = &quot;Cuantiles muestrales&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
</div>
<div id="section-test-anderson-darling" class="section level3">
<h3>Test Anderson-Darling</h3>
<p>El test de Anderson-Darling es una prueba estadística que evalúa si
un conjunto de datos sigue una distribución teórica, en este caso, la
distribución normal. A diferencia del test de Shapiro-Wilk, este test
pone mayor énfasis en las colas de la distribución, lo que lo hace
especialmente sensible a desviaciones en los extremos. El método se basa
en comparar la función de distribución empírica de la muestra con la
función de distribución teórica esperada. El estadístico del test se
calcula a partir de la suma ponderada de las diferencias entre ambas
funciones. Un valor alto del estadístico indica una discrepancia
significativa, sugiriendo que los datos pueden no seguir una
distribución normal</p>
<pre class="r"><code>x &lt;- iris$Sepal.Length
n &lt;- length(x)

x_sorted &lt;- sort(x)

x_mean &lt;- mean(x_sorted)
x_sd &lt;- sd(x_sorted)

z &lt;- (x_sorted - x_mean) / x_sd

F_z &lt;- pnorm(z)

i &lt;- 1:n
A2 &lt;- -n - (1/n) * sum((2*i - 1) * (log(F_z) + log(1 - rev(F_z))))

cat(&quot;Estadístico A² calculado manualmente:&quot;, A2, &quot;\n&quot;)</code></pre>
<pre><code>## Estadístico A² calculado manualmente: 0.8891995</code></pre>
<p>valores_criticos &lt;- c(“15%” = 0.576, “10%” = 0.656, “5%” = 0.787,
“2.5%” = 0.918, “1%” = 1.092)</p>
<pre class="r"><code># Cargar el paquete nortest (instalar si es necesario)
if (!require(nortest)) {
  install.packages(&quot;nortest&quot;)
  library(nortest)
}

# Test de Anderson-Darling para Sepal.Length
ad_result &lt;- ad.test(iris$Sepal.Length)
print(ad_result)</code></pre>
<pre><code>## 
##  Anderson-Darling normality test
## 
## data:  iris$Sepal.Length
## A = 0.8892, p-value = 0.02251</code></pre>
<pre class="r"><code>ggplot(iris, aes(x = Sepal.Length)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = &quot;skyblue&quot;, color = &quot;black&quot;) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(iris$Sepal.Length), sd = sd(iris$Sepal.Length)), 
                color = &quot;red&quot;, size = 1) +
  labs(title = &quot;Histograma de Sepal.Length con curva normal&quot;,
       x = &quot;Sepal.Length&quot;, y = &quot;Densidad&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<pre class="r"><code>normal_real &lt;- rnorm(200, mean = 15, sd = 3)

ad_result2 &lt;- ad.test(normal_real)
print(ad_result2)</code></pre>
<pre><code>## 
##  Anderson-Darling normality test
## 
## data:  normal_real
## A = 0.95107, p-value = 0.01593</code></pre>
<pre class="r"><code>df &lt;- data.frame(normal_real)

ggplot(df, aes(x = normal_real)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = &quot;lightgreen&quot;, color = &quot;black&quot;) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(normal_real), sd = sd(normal_real)), 
                color = &quot;blue&quot;, size = 1) +
  labs(title = &quot;Histograma con curva normal&quot;,
       x = &quot;Valor&quot;, y = &quot;Densidad&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
</div>
</div>
<div id="section-test-de-homocedasticidad" class="section level2">
<h2>6. Test de Homocedasticidad</h2>
<div id="section-concepto-y-uso-4" class="section level3">
<h3>Concepto y Uso</h3>
<p>El test de homocedasticidad evalúa si la varianza de los datos es la
misma en distintos grupos, lo cual es un supuesto fundamental en muchos
tests paramétricos.<br />
- <strong>Métodos comunes:</strong><br />
- Test de Bartlett (más sensible a la normalidad).<br />
- Test de Levene (más robusto).</p>
</div>
<div id="section-ejemplo-práctico-3" class="section level3">
<h3>Ejemplo Práctico</h3>
<p>Utilizaremos el dataset <em>iris</em> para evaluar si la varianza de
<em>Sepal.Length</em> es homogénea entre las especies mediante el test
de Bartlett.</p>
<pre class="r"><code>data &lt;- iris
grupo1 &lt;- data$Sepal.Length[data$Species == &quot;setosa&quot;]
grupo2 &lt;- data$Sepal.Length[data$Species == &quot;versicolor&quot;]
grupo3 &lt;- data$Sepal.Length[data$Species == &quot;virginica&quot;]

n1 &lt;- length(grupo1)
n2 &lt;- length(grupo2)
n3 &lt;- length(grupo3)

s1_sq &lt;- var(grupo1)
s2_sq &lt;- var(grupo2)
s3_sq &lt;- var(grupo3)

N &lt;- n1 + n2 + n3
k &lt;- 3

sp_sq &lt;- ((n1 - 1)*s1_sq + (n2 - 1)*s2_sq + (n3 - 1)*s3_sq) / (N - k)

ln_sp &lt;- log(sp_sq)
ln_s &lt;- (n1 - 1)*log(s1_sq) + (n2 - 1)*log(s2_sq) + (n3 - 1)*log(s3_sq)

numerador &lt;- (N - k)*ln_sp - ln_s
denominador &lt;- 1 + (1/(3*(k - 1))) * ((1/(n1 - 1)) + (1/(n2 - 1)) + (1/(n3 - 1)) - (1/(N - k)))

Testad &lt;- numerador / denominador
p_valor &lt;- 1 - pchisq(Testad, df = k - 1)

cat(&quot;Estadístico de Bartlett T:&quot;, Testad, &quot;\n&quot;)</code></pre>
<pre><code>## Estadístico de Bartlett T: 16.0057</code></pre>
<pre class="r"><code>cat(&quot;p-valor:&quot;, p_valor, &quot;\n&quot;)</code></pre>
<pre><code>## p-valor: 0.0003345076</code></pre>
<pre class="r"><code># Test de homocedasticidad con Bartlett
bartlett_result &lt;- bartlett.test(Sepal.Length ~ Species, data = iris)
print(bartlett_result)</code></pre>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Sepal.Length by Species
## Bartlett&#39;s K-squared = 16.006, df = 2, p-value = 0.0003345</code></pre>
<pre class="r"><code># Visualización: Boxplot de Sepal.Length por Species
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = &quot;Boxplot de Sepal.Length por Species&quot;,
       x = &quot;Species&quot;, y = &quot;Sepal.Length&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
</div>
<div id="section-ejercicio-1-bootstrapping-para-proporciones"
class="section level3">
<h3>Ejercicio 1: Bootstrapping para Proporciones</h3>
<p>Simule una muestra de 150 observaciones de una variable categórica
con niveles “Aprobado” y “Reprobado” donde la probabilidad de “Aprobado”
sea 0.70.<br />
- Calcule la proporción original de “Aprobado”.<br />
- Realice 2000 réplicas de bootstrapping para estimar dicha
proporción.<br />
- Obtenga el intervalo de confianza al 95% y grafique la distribución de
las proporciones obtenidas.</p>
</div>
<div id="section-ejercicio-2-test-de-permutaciones-para-proporciones"
class="section level3">
<h3>Ejercicio 2: Test de Permutaciones para Proporciones</h3>
<p>Simule dos grupos con 100 observaciones cada uno.<br />
- En el Grupo 1, la proporción de “Aprobado” es 0.80; en el Grupo 2, es
0.65.<br />
- Realice un test de permutaciones con 3000 réplicas para evaluar si la
diferencia en proporciones es significativa.<br />
- Grafique la distribución de las diferencias permutadas y reporte el
p‑valor.</p>
</div>
<div id="section-ejercicio-3-test-de-homogeneidad"
class="section level3">
<h3>Ejercicio 3: Test de Homogeneidad</h3>
<p>Utilice datos simulados para tres regiones donde se clasifica la
preferencia de un producto en tres niveles: Alta, Media y Baja.<br />
- Construya la tabla de contingencia.<br />
- Realice el test de homogeneidad (chi-cuadrado) para evaluar si la
distribución de preferencias es similar entre las regiones.<br />
- Interprete el p‑valor.</p>
</div>
<div id="section-ejercicio-4-test-exacto-de-fisher"
class="section level3">
<h3>Ejercicio 4: Test Exacto de Fisher</h3>
<p>Simule una tabla 2×2 con datos pequeños para las variables “Uso de
medicamento” (Sí/No) y “Recuperación” (Mejora/No mejora) con un total de
20 observaciones.<br />
- Realice el test exacto de Fisher.<br />
- Interprete el p‑valor y concluya sobre la asociación.</p>
</div>
<div id="section-ejercicio-5-test-de-homocedasticidad"
class="section level3">
<h3>Ejercicio 5: Test de Homocedasticidad</h3>
<p>Utilice el dataset <em>iris</em> o simule tres grupos de datos
numéricos.<br />
- Realice un test de homocedasticidad (puede usar el test de Bartlett)
para evaluar si las varianzas son iguales entre los grupos.<br />
- Reporte el p‑valor y concluya si se cumple el supuesto de igualdad de
varianzas.</p>
</div>
<div id="section-ejercicio-6-test-de-normalidad" class="section level3">
<h3>Ejercicio 6: Test de Normalidad</h3>
<p>Utilice la variable <em>mpg</em> del dataset <em>mtcars</em>.<br />
- Realice el test de normalidad utilizando el test de
Shapiro-Wilk.<br />
- Genere un Q-Q plot para visualizar la normalidad.<br />
- Interprete los resultados.</p>
</div>
<div id="section-ejercicio-integrador" class="section level3">
<h3>Ejercicio Integrador</h3>
<p>Utilizando el dataset <em>iris</em> y simulaciones, realice lo
siguiente: 1. Cree una variable categórica “Ancho_Sepal” a partir de
<em>Sepal.Width</em> (defina “Ancho” si el valor es mayor o igual a la
mediana y “Estrecho” si es menor). 2. Realice un test de homogeneidad
para evaluar si la distribución de “Ancho_Sepal” es la misma entre las
tres especies. 3. Realice un test de normalidad sobre la variable
<em>Sepal.Length</em>. 4. Realice un test de homocedasticidad para
comparar la varianza de <em>Sepal.Length</em> entre las especies. 5.
Presente visualizaciones: gráfico de barras para “Ancho_Sepal” por
especie, Q-Q plot para <em>Sepal.Length</em> y boxplots de
<em>Sepal.Length</em> por especie.</p>
</div>
</div>
</div>
<div id="section-sección-de-resoluciones" class="section level1">
<h1>Sección de Resoluciones</h1>
<div id="section-resolución-ejercicio-1-bootstrapping-para-proporciones"
class="section level2">
<h2>Resolución Ejercicio 1: Bootstrapping para Proporciones</h2>
<pre class="r"><code>set.seed(101)
# Simulación de 150 observaciones con probabilidad 0.70 para &quot;Aprobado&quot;
resultados &lt;- sample(c(&quot;Aprobado&quot;, &quot;Reprobado&quot;), size = 150, replace = TRUE, prob = c(0.70, 0.30))
prop_original &lt;- mean(resultados == &quot;Aprobado&quot;)
cat(&quot;Proporción original de &#39;Aprobado&#39;:&quot;, round(prop_original, 2), &quot;\n&quot;)</code></pre>
<pre><code>## Proporción original de &#39;Aprobado&#39;: 0.67</code></pre>
<pre class="r"><code># Bootstrapping: 2000 réplicas
n_boot &lt;- 2000
boot_prop &lt;- replicate(n_boot, {
  muestra_boot &lt;- sample(resultados, size = length(resultados), replace = TRUE)
  mean(muestra_boot == &quot;Aprobado&quot;)
})
CI &lt;- quantile(boot_prop, probs = c(0.025, 0.975))
cat(&quot;Intervalo de confianza 95%:&quot;, round(CI[1],2), &quot;-&quot;, round(CI[2],2), &quot;\n&quot;)</code></pre>
<pre><code>## Intervalo de confianza 95%: 0.6 - 0.75</code></pre>
<pre class="r"><code># Gráfica
library(ggplot2)
df_boot &lt;- data.frame(prop = boot_prop)
ggplot(df_boot, aes(x = prop)) +
  geom_histogram(bins = 30, fill = &quot;skyblue&quot;, color = &quot;black&quot;, alpha = 0.7) +
  geom_vline(xintercept = CI, color = &quot;red&quot;, linetype = &quot;dashed&quot;, size = 1) +
  labs(title = &quot;Bootstrapping: Proporción de &#39;Aprobado&#39;&quot;,
       x = &quot;Proporción&quot;, y = &quot;Frecuencia&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
</div>
<div
id="section-resolución-ejercicio-2-test-de-permutaciones-para-proporciones"
class="section level2">
<h2>Resolución Ejercicio 2: Test de Permutaciones para Proporciones</h2>
<pre class="r"><code>set.seed(202)
n &lt;- 100
grupo &lt;- rep(c(&quot;Grupo1&quot;, &quot;Grupo2&quot;), each = n)
datos &lt;- data.frame(grupo, 
                    resultado = c(
                      sample(c(&quot;Aprobado&quot;, &quot;Reprobado&quot;), n, replace = TRUE, prob = c(0.80, 0.20)),
                      sample(c(&quot;Aprobado&quot;, &quot;Reprobado&quot;), n, replace = TRUE, prob = c(0.65, 0.35))
                    ))
prop_g1 &lt;- mean(datos$resultado[datos$grupo == &quot;Grupo1&quot;] == &quot;Aprobado&quot;)
prop_g2 &lt;- mean(datos$resultado[datos$grupo == &quot;Grupo2&quot;] == &quot;Aprobado&quot;)
diff_obs &lt;- prop_g1 - prop_g2
cat(&quot;Diferencia observada (Grupo1 - Grupo2):&quot;, round(diff_obs, 3), &quot;\n&quot;)</code></pre>
<pre><code>## Diferencia observada (Grupo1 - Grupo2): 0.18</code></pre>
<pre class="r"><code># Permutación: 3000 réplicas
n_perm &lt;- 3000
dif_perm &lt;- replicate(n_perm, {
  grupo_perm &lt;- sample(datos$grupo)
  p1 &lt;- mean(datos$resultado[grupo_perm == &quot;Grupo1&quot;] == &quot;Aprobado&quot;)
  p2 &lt;- mean(datos$resultado[grupo_perm == &quot;Grupo2&quot;] == &quot;Aprobado&quot;)
  p1 - p2
})
p_valor_perm &lt;- mean(abs(dif_perm) &gt;= abs(diff_obs))
cat(&quot;p-valor (permutación):&quot;, round(p_valor_perm, 4), &quot;\n&quot;)</code></pre>
<pre><code>## p-valor (permutación): 0.0087</code></pre>
<pre class="r"><code># Gráfica
df_perm &lt;- data.frame(diff = dif_perm)
ggplot(df_perm, aes(x = diff)) +
  geom_histogram(bins = 30, fill = &quot;lightgreen&quot;, color = &quot;black&quot;, alpha = 0.7) +
  geom_vline(xintercept = diff_obs, color = &quot;red&quot;, linetype = &quot;dashed&quot;, size = 1.2) +
  labs(title = &quot;Permutación: Diferencia en Proporciones&quot;,
       x = &quot;Diferencia (Grupo1 - Grupo2)&quot;, y = &quot;Frecuencia&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
</div>
<div id="section-resolución-ejercicio-3-test-de-homogeneidad"
class="section level2">
<h2>Resolución Ejercicio 3: Test de Homogeneidad</h2>
<pre class="r"><code>set.seed(303)
# Simulación para tres regiones con tres niveles de preferencia
region &lt;- rep(c(&quot;Región1&quot;, &quot;Región2&quot;, &quot;Región3&quot;), each = 100)
preferencia &lt;- sample(c(&quot;Alta&quot;, &quot;Media&quot;, &quot;Baja&quot;), size = 300, replace = TRUE,
                       prob = c(0.5, 0.3, 0.2))
datos_homo &lt;- data.frame(region, preferencia)
tabla &lt;- table(datos_homo$region, datos_homo$preferencia)
print(tabla)</code></pre>
<pre><code>##          
##           Alta Baja Media
##   Región1   49   20    31
##   Región2   42   22    36
##   Región3   59   20    21</code></pre>
<pre class="r"><code># Test de homogeneidad (chi-cuadrado)
test_homo &lt;- chisq.test(tabla)
print(test_homo)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tabla
## X-squared = 7.0263, df = 4, p-value = 0.1345</code></pre>
</div>
<div id="section-resolución-ejercicio-4-test-exacto-de-fisher"
class="section level2">
<h2>Resolución Ejercicio 4: Test Exacto de Fisher</h2>
<pre class="r"><code># Simulación de una tabla 2x2 con 20 observaciones totales
tabla_f &lt;- matrix(c(4, 3, 2, 5), nrow = 2,
                  dimnames = list(&quot;Uso_Medicamento&quot; = c(&quot;Sí&quot;, &quot;No&quot;),
                                  &quot;Recuperación&quot; = c(&quot;Mejora&quot;, &quot;No mejora&quot;)))
print(tabla_f)</code></pre>
<pre><code>##                Recuperación
## Uso_Medicamento Mejora No mejora
##              Sí      4         2
##              No      3         5</code></pre>
<pre class="r"><code># Test exacto de Fisher
test_fisher &lt;- fisher.test(tabla_f)
print(test_fisher)</code></pre>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tabla_f
## p-value = 0.5921
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##   0.2418801 55.2697930
## sample estimates:
## odds ratio 
##   3.043639</code></pre>
</div>
<div id="section-resolución-ejercicio-5-test-de-homocedasticidad"
class="section level2">
<h2>Resolución Ejercicio 5: Test de Homocedasticidad</h2>
<pre class="r"><code># Utilizando el dataset iris
data(iris)
# Test de homocedasticidad con Bartlett
test_bartlett &lt;- bartlett.test(Sepal.Length ~ Species, data = iris)
print(test_bartlett)</code></pre>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Sepal.Length by Species
## Bartlett&#39;s K-squared = 16.006, df = 2, p-value = 0.0003345</code></pre>
<pre class="r"><code># Visualización: Boxplot
library(ggplot2)
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = &quot;Boxplot: Sepal.Length por Species&quot;,
       x = &quot;Species&quot;, y = &quot;Sepal.Length&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
</div>
<div id="section-resolución-ejercicio-6-test-de-normalidad"
class="section level2">
<h2>Resolución Ejercicio 6: Test de Normalidad</h2>
<pre class="r"><code># Utilizando la variable mpg del dataset mtcars
data(mtcars)
test_shapiro &lt;- shapiro.test(mtcars$mpg)
print(test_shapiro)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  mtcars$mpg
## W = 0.94756, p-value = 0.1229</code></pre>
<pre class="r"><code># Q-Q plot
ggplot(mtcars, aes(sample = mpg)) +
  stat_qq(color = &quot;blue&quot;) +
  stat_qq_line(color = &quot;red&quot;) +
  labs(title = &quot;Q-Q Plot de mpg&quot;, x = &quot;Cuantiles teóricos&quot;, y = &quot;Cuantiles muestrales&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
</div>
<div id="section-resolución-ejercicio-integrador"
class="section level2">
<h2>Resolución Ejercicio Integrador</h2>
<pre class="r"><code># Utilizando el dataset iris
data(iris)
# 1. Crear variable categórica &quot;Ancho_Sepal&quot; a partir de Sepal.Width
iris$Ancho_Sepal &lt;- ifelse(iris$Sepal.Width &gt;= median(iris$Sepal.Width), &quot;Ancho&quot;, &quot;Estrecho&quot;)
tabla_integrador &lt;- table(iris$Species, iris$Ancho_Sepal)
cat(&quot;Tabla de contingencia (Species vs. Ancho_Sepal):\n&quot;)</code></pre>
<pre><code>## Tabla de contingencia (Species vs. Ancho_Sepal):</code></pre>
<pre class="r"><code>print(tabla_integrador)</code></pre>
<pre><code>##             
##              Ancho Estrecho
##   setosa        48        2
##   versicolor    16       34
##   virginica     29       21</code></pre>
<pre class="r"><code># 2. Test de homogeneidad para Ancho_Sepal
test_homogeneidad &lt;- chisq.test(tabla_integrador)
print(test_homogeneidad)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tabla_integrador
## X-squared = 43.973, df = 2, p-value = 2.828e-10</code></pre>
<pre class="r"><code># Visualización: gráfico de barras
ggplot(iris, aes(x = Species, fill = Ancho_Sepal)) +
  geom_bar(position = &quot;fill&quot;) +
  labs(title = &quot;Distribución de &#39;Ancho_Sepal&#39; por Species&quot;,
       x = &quot;Species&quot;, y = &quot;Proporción&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<pre class="r"><code># 3. Test de normalidad para Sepal.Length
test_normalidad &lt;- shapiro.test(iris$Sepal.Length)
print(test_normalidad)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  iris$Sepal.Length
## W = 0.97609, p-value = 0.01018</code></pre>
<pre class="r"><code># Q-Q plot para Sepal.Length
ggplot(iris, aes(sample = Sepal.Length)) +
  stat_qq(color = &quot;blue&quot;) +
  stat_qq_line(color = &quot;red&quot;) +
  labs(title = &quot;Q-Q Plot de Sepal.Length&quot;,
       x = &quot;Cuantiles teóricos&quot;, y = &quot;Cuantiles muestrales&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-51-2.png" width="672" /></p>
<pre class="r"><code># 4. Test de homocedasticidad para Sepal.Length entre Species (usando Bartlett)
test_homocedasticidad &lt;- bartlett.test(Sepal.Length ~ Species, data = iris)
print(test_homocedasticidad)</code></pre>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Sepal.Length by Species
## Bartlett&#39;s K-squared = 16.006, df = 2, p-value = 0.0003345</code></pre>
<pre class="r"><code># Visualización: Boxplot de Sepal.Length por Species
ggplot(iris, aes(x = Species, y = Sepal.Length, fill = Species)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = &quot;Boxplot de Sepal.Length por Species&quot;,
       x = &quot;Species&quot;, y = &quot;Sepal.Length&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-51-3.png" width="672" /></p>
</div>
<div id="section-test-de-independencia-1" class="section level2">
<h2>Test de Independencia</h2>
<p>El <strong>test de independencia</strong> se utiliza para determinar
si dos variables categóricas están asociadas o si son independientes.
Esto se logra mediante el análisis de una tabla de contingencia que
resume las frecuencias observadas en cada combinación de categorías y, a
partir de ella, se calcula la estadística chi-cuadrado.</p>
<div id="section-cómo-funciona" class="section level3">
<h3>¿Cómo Funciona?</h3>
<ol style="list-style-type: decimal">
<li><p><strong>Construcción de la Tabla de Contingencia:</strong><br />
Se cuentan las ocurrencias de cada combinación de categorías. Por
ejemplo, en el dataset <em>iris</em>, podemos crear una variable
categórica a partir de <em>Sepal.Width</em>:</p>
<ul>
<li>Se define “Ancho” si el valor es mayor o igual a la mediana.</li>
<li>Se define “Estrecho” si es menor que la mediana.</li>
</ul></li>
<li><p><strong>Cálculo de la Estadística Chi-cuadrado:</strong><br />
Se comparan las frecuencias observadas con las esperadas (suponiendo
independencia). La estadística resultante evalúa la discrepancia entre
ambas; un valor alto (con p‑valor pequeño) indica que es poco probable
que las diferencias se deban al azar, lo que sugiere que las variables
no son independientes.</p></li>
<li><p><strong>Interpretación del p‑valor:</strong></p>
<ul>
<li><strong>p‑valor &lt; 0.05:</strong> Se rechaza la hipótesis nula de
independencia y se concluye que existe asociación entre las
variables.<br />
</li>
<li><strong>p‑valor ≥ 0.05:</strong> No se rechaza la hipótesis nula,
sugiriendo que no hay evidencia suficiente para afirmar que las
variables están asociadas.</li>
</ul></li>
</ol>
</div>
<div id="section-ejemplo-práctico-con-el-dataset-iris"
class="section level3">
<h3>Ejemplo Práctico con el Dataset <em>iris</em></h3>
<p>En este ejemplo, se crea la variable categórica
<strong>Ancho_Sepal</strong> a partir de <em>Sepal.Width</em> y se
evalúa si existe asociación entre <strong>Species</strong> y
<strong>Ancho_Sepal</strong>.</p>
<pre class="r"><code># Utilizando el dataset iris
data(iris)

# Crear variable categórica &quot;Ancho_Sepal&quot; a partir de Sepal.Width:
# &quot;Ancho&quot; si el valor es mayor o igual a la mediana, &quot;Estrecho&quot; si es menor.
iris$Ancho_Sepal &lt;- ifelse(iris$Sepal.Width &gt;= median(iris$Sepal.Width), &quot;Ancho&quot;, &quot;Estrecho&quot;)

# Construcción de la tabla de contingencia
tabla_indep &lt;- table(iris$Species, iris$Ancho_Sepal)
print(tabla_indep)</code></pre>
<pre><code>##             
##              Ancho Estrecho
##   setosa        48        2
##   versicolor    16       34
##   virginica     29       21</code></pre>
<pre class="r"><code># Realización del test de independencia (chi-cuadrado)
test_indep &lt;- chisq.test(tabla_indep)
print(test_indep)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tabla_indep
## X-squared = 43.973, df = 2, p-value = 2.828e-10</code></pre>
</div>
<div id="section-visualización-con-ggplot2" class="section level3">
<h3>Visualización con ggplot2</h3>
<p>La siguiente gráfica muestra la proporción de observaciones en cada
categoría de <strong>Ancho_Sepal</strong> para cada
<strong>Species</strong>. La visualización facilita la interpretación de
la distribución de las frecuencias.</p>
<pre class="r"><code>library(ggplot2)
ggplot(iris, aes(x = Species, fill = Ancho_Sepal)) +
  geom_bar(position = &quot;fill&quot;) +
  labs(title = &quot;Proporción de &#39;Ancho_Sepal&#39; según Species&quot;,
       x = &quot;Especie&quot;,
       y = &quot;Proporción&quot;,
       fill = &quot;Ancho_Sepal&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
</div>
</div>
<div id="section-ejercicio-test-de-independencia"
class="section level2">
<h2>Ejercicio Test de independencia</h2>
<p>Simule un dataset de 200 observaciones con dos variables
categóricas:<br />
- <strong>Color:</strong> con niveles “Rojo” y “Verde” (donde la
probabilidad de “Rojo” es 60% y “Verde” 40%).<br />
- <strong>Aprobación:</strong> con niveles “Sí” y “No”.<br />
- Para las observaciones de color “Rojo”, la probabilidad de “Sí” es 55%
y de “No” 45%.<br />
- Para las observaciones de color “Verde”, la probabilidad de “Sí” es
50% y de “No” 50%.</p>
<p>Realice un test de independencia para evaluar si existe relación
entre el <strong>Color</strong> y la <strong>Aprobación</strong> y
visualice la distribución de las proporciones.</p>
</div>
<div id="section-ejercicio-bonus" class="section level2">
<h2>Ejercicio Bonus</h2>
<p>Hagan lo mismo pero en vez de tamaño de muestra fijo en 200, para
cada posible tamaño de muestra entre 100 y 4000 (intervalos cada 100), y
visualizenlo con el eje x el tamaño de la muestra y en el eje y el
p-valor obtenido en el test.</p>
<div id="section-resolución-del-ejercicio" class="section level3">
<h3>Resolución del Ejercicio</h3>
<pre class="r"><code>set.seed(123)
# Generar la variable &quot;Color&quot; con 200 observaciones
color &lt;- sample(c(&quot;Rojo&quot;, &quot;Verde&quot;), size = 200, replace = TRUE, prob = c(0.6, 0.4))

# Generar la variable &quot;Aprobación&quot; dependiendo del valor de &quot;Color&quot;
aprobacion &lt;- sapply(color, function(x) {
  if (x == &quot;Rojo&quot;) {
    sample(c(&quot;Sí&quot;, &quot;No&quot;), size = 1, prob = c(0.55, 0.45))
  } else {
    sample(c(&quot;Sí&quot;, &quot;No&quot;), size = 1, prob = c(0.5, 0.5))
  }
})

# Crear el dataframe
datos &lt;- data.frame(Color = color, Aprobacion = aprobacion)

# Construcción de la tabla de contingencia
tabla_ej &lt;- table(datos$Color, datos$Aprobacion)
print(tabla_ej)</code></pre>
<pre><code>##        
##         No Sí
##   Rojo  53 69
##   Verde 45 33</code></pre>
<pre class="r"><code># Realización del test de independencia
test_ej &lt;- chisq.test(tabla_ej)
print(test_ej)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  tabla_ej
## X-squared = 3.3169, df = 1, p-value = 0.06857</code></pre>
<pre class="r"><code># Visualización de la distribución de las proporciones con ggplot2
ggplot(datos, aes(x = Color, fill = Aprobacion)) +
  geom_bar(position = &quot;fill&quot;) +
  labs(title = &quot;Proporción de Aprobación según Color&quot;,
       x = &quot;Color&quot;,
       y = &quot;Proporción&quot;,
       fill = &quot;Aprobación&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-54-1.png" width="672" />
## Resolucion ejercicio bonus</p>
<pre class="r"><code>set.seed(123)
library(ggplot2)

# Definir una secuencia de tamaños de muestra de 5 a 400 (pasos de 5)
tamanos &lt;- seq(100, 4000, by = 100)

# Función para simular el dataset y obtener el p-valor del test de independencia
obtener_pvalor &lt;- function(n) {
  # Simular la variable &quot;Color&quot;
  color &lt;- sample(c(&quot;Rojo&quot;, &quot;Verde&quot;), size = n, replace = TRUE, prob = c(0.6, 0.4))
  
  # Generar la variable &quot;Aprobacion&quot; en función de &quot;Color&quot;
  aprobacion &lt;- sapply(color, function(x) {
    if(x == &quot;Rojo&quot;) {
      sample(c(&quot;Sí&quot;, &quot;No&quot;), size = 1, prob = c(0.55, 0.45))
    } else {
      sample(c(&quot;Sí&quot;, &quot;No&quot;), size = 1, prob = c(0.5, 0.5))
    }
  })
  
  datos_temp &lt;- data.frame(Color = color, Aprobacion = aprobacion)
  
  # Construir la tabla de contingencia. Si falta alguna categoría (por ejemplo, en muestras muy pequeñas),
  # se rellena con 0 para mantener las dimensiones.
  tabla &lt;- with(datos_temp, table(factor(Color, levels = c(&quot;Rojo&quot;, &quot;Verde&quot;)),
                                  factor(Aprobacion, levels = c(&quot;Sí&quot;, &quot;No&quot;))))
  
  # Para tamaños muy pequeños puede ocurrir que no haya suficiente información, por lo que se usa NA
  if(any(dim(tabla) &lt; 2) || any(tabla == 0)) {
    p_val &lt;- NA
  } else {
    p_val &lt;- chisq.test(tabla)$p.value
  }
  
  return(p_val)
}

# Aplicar la función a cada tamaño de muestra
p_valores &lt;- sapply(tamanos, obtener_pvalor)

# Crear dataframe para la visualización
df_p &lt;- data.frame(Tamano = tamanos, p_valor = p_valores)

# Graficar el p-valor en función del tamaño de la muestra
ggplot(df_p, aes(x = Tamano, y = p_valor)) +
  geom_line(color = &quot;darkblue&quot;) +
  geom_point(color = &quot;darkblue&quot;) +
  geom_hline(yintercept = 0.05, linetype = &quot;dashed&quot;, color = &quot;red&quot;) +  # Línea de rechazo
  labs(title = &quot;Cambio del p-valor en función del tamaño de la muestra&quot;,
       x = &quot;Tamaño de la muestra&quot;,
       y = &quot;p-valor&quot;) +
  theme_minimal()</code></pre>
<p><img src="practica3_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
